3. Argument of Inherent Controllability and Predictability in AI Systems

Artificial Intelligence systems, being the products of human ingenuity, embody an element of controllability that is inherent to their design. This is a foundational premise that supports the assertion that AI can be safe for use. The meticulous design process of AI systems ensures that their behavior and functionality are not arbitrary but are instead subject to the intentions and constraints set by their creators. This level of predictability and controllability inherently reduces the risk associated with AI systems acting in unforeseen or potentially harmful ways.

Delving into the realm of machine learning interpretability, we find tools that dissect the decision-making processes of AI, illuminating the once opaque 'black box' of their inner workings. This interpretability is not merely a passive observation; it equips us with the knowledge to both detect and rectify any undesirable behavior that may emerge within these systems. By understanding the mechanics of AI decisions, we can steer these systems towards outcomes that align with our safety standards and ethical expectations.

Advancements in the field have led to the development of Explainable AI, which can articulate its reasoning in comprehensible terms. This not only bolsters our grasp of AI behavior but also instills a greater level of confidence in the system's adherence to our directives. Explainable AI serves as a critical tool in the ongoing effort to align AI systems with human values and intentions, thereby ensuring that as they approach and even surpass human performance in specific domains, they remain within our sphere of control. 

Moreover, the envisioned slow progression of AI capabilities offers a strategic advantage. It allows for extensive periods of observation, experimentation, and learning, which are essential for understanding and aligning AI systems. This gradual approach affords us the opportunity to harness the potential of AI, gaining valuable insights into their motivational systems, without precipitating the risk of losing control over them. By maintaining AI at a level where it is highly capable yet not so advanced as to be uncontrollable, we can safely explore and implement solutions to the alignment problem, thereby securing the safe application of AI. 

The trajectory towards superhuman AI capabilities is one that should be navigated with a blend of caution and optimism, leveraging our ability to understand, predict, and control these systems, thus securing AI as a safe and beneficial tool for humanity.