Speaker 1
Good evening, everyone. Sorry we're a little late. So tonight we debate AI, the motion that this house believes artificial intelligence is an existential threat. And we're honored tonight to be joined by a particular distinguished individuals. In proposition, we have Connolly, Rebecca Gorman and Professor Joanna Bryson. While in opposition, Professor Judy Weisman, Dr. Indra Joshi are joined by student Speaker Igor Sterner from Pembroke College. Before we begin, let's just recap the format for the evening. So each paper speaker tonight has ten minutes to make their case. The first and last minutes are protected time, so please do not try and poi them during that time. But as members, this is your house and welcome contributions from all. So between each round of paper speakers, there will be time for speeches from the floor in proposition opposition and abstention.

Speaker 1
Should you wish to make one of these, please just put your hand up when the moment comes and wait for the microphone to come to you. Don't forget to say your name in college. And finally, if you wish to make a poi, please remember to keep it short and polite. Right, let's get started. Opening the debate tonight is Mr. Connolly. Connolly is the CEO of AI startup conjecture, working on understanding large ML models and aligning them with human values. He is also the founder of Eluta AI, a decentralized, grassroots collection of volunteer researchers, engineers and developers focused on AI alignment, scaling and open source AI research. Connor, you have the floor.

Speaker 2
Thank you so much, everyone. It was a real pleasure to be invited here today. When I first received word that I was invited to a debate at an illustrious english university, there was a brief moment of horror where I thought I might have to go to Oxford. Luckily, I find myself in the lovely halls of Cambridge University. So the motion tonight is that the house believes that artificial intelligence is an existential threat. And there is a common temptation in a new generation of young technologists such as myself to think of ourselves, of every new debate, every new idea, every new topic have we come up with as novel and unique while forgetting the history of the great minds that came before us?

Speaker 2
In 1951, there lived a man named Alan Turing, the father of computer science, a titan of his field, a hero of World War II, and a tragic figure driven to suicide by his own country's intolerance for his nonstandard sexuality. In 1951, Alan Turing gave a lecture in Manchester entitled Intelligent Machinery, a heretical theory exploring the consequences of building computer systems capable of displaying intelligence. In this lecture, he said, for it seems probable that once the machine thinking method had started, it might take long to outstrip our feeble powers, there would be no question of the machines dying, and they would be able to converse with each other, to sharpen their wits. At some stage, therefore, we should have to expect the machines to take control.

Speaker 2
And so, as we stand at the dawn of a new age of unprecedented AI progress, it is tempting to think of this topic as just a novel fad of eccentric of AGI, rather than a fundamental question that has been with us since the very beginning of the field of computer science. The definition of existential risk is a risk that threatens the premature extinction of humanity, or the permanent and drastic destruction of its potential for desirable future development, the loss of control of our future. And if we build machines that are more intelligent, more competent in people, that are more capable at manipulation, deception, politics, science, business, and everything else, and we do not control them, then the future will belong to them, not to us. Everything else derives from this simple observation.

Speaker 2
Now, I don't claim to have the true definition of intelligence, the true definition of reasoning, any of these things, but I also don't care. What I care about is competence. I care about the ability to solve problems, to gain power. And many of our greatest scientists, engineers, companies are striving to build such machines of competence, and I expect them to succeed. And let us be clear that the development of fully autonomous AGI agents that act in the real world is the deliberate goal of companies such as DeepMind, OpenAI and others, even enshrined in their very charters, while at the same time our progress on being able to control and understand such minds is progressing at a pitiful rate. The danger does not come from some evil property that must be removed from such systems. It comes from power, from competence.

Speaker 2
If you build extraordinarily competent machines, autonomous machines, that you do not control well, the consequences should be evident. This is not to say that there is not incredible benefits that can be had from many applications of AI. 99% of AI applications are narrow rather than general autonomous AGI systems, applications in science and healthcare, in so many other wonderful applications, and these benefits should be reaped. This is not to say that these narrow applications cannot also bear harms. Of course they can. Like with any new technology, the fact that narrow AI poses grave harms to groups, both broad and vulnerable, can coexist naturally with the fact that existential risks from general powerful AI threatens all humans of all groups.

Speaker 2
The harms affecting all groups are not just from negligence, though there is plenty of that as well, but also because we, simply on a purely technical level, do not know how to understand and control general intelligence to make it so that it gives us what we want, instead of risking the survival of all. This risk is freely acknowledged by the very people who are building it, the unelected, unaccountable technologists who are willfully running an unacceptably risky experiment on every single man, woman and child on the planet without their consent. Addressing existential risk is a crucial component of mitigating harm towards vulnerable groups in our world, and dismissing it would be of unconscionable negligence towards the marginalized and vulnerable, the same way that we must not neglect or dismiss the other constant looming threats such as climate change or nuclear war.

Speaker 2
When I think of how I expect existential risk to manifest, I do not think it will be with a bang, but with a whimper. As systems develop, become more competent, more powerful, more people will delegate more of their thinking to these machines. Ceos will outsource their business decisions. They will handle trading design products, write code, litigate disputes, manage political campaigns, develop technology ways to disinformation warfare. The world will become ever more confusing, more hostile, more impenetrable, both intentionally and unintentionally on the behalf of their developers wielders. We will see geopolitical events unfold that are so obscured by fake narratives that if it becomes impossible to discern truth from fiction, aipowered lawyers and lawsuits twisting the justice system to levels of perverse complexity utterly impenetrable to any human.

Speaker 2
New technologies being invented that people can barely understand their function or where they even came from, market movements of such violence and unpredictability that no human trader can stay in the game. A whirlwind, confusing world of such speed and dark complexity that the unaugmented human without AI assistance is the sitting duck to aipowered manipulation and exploitation until eventually, quite unceremoniously, humanity is simply no longer in control and the future will be fully in the hands of inscrutable machines that we cannot hope to understand or to control. Could we solve this problem, create AI that empowers us rather than disempowering? This is the same type of question such as can we build a nuclear reactor that is safe? Can we create social media that is beneficial to its users health? Can we create a government and rule of law? That is just?

Speaker 2
My answer to all these questions is yes, it is possible, but it is not what happens by default. It requires deliberate effort and brilliance. Applied to these problems, there is no law of nature that forbids us from solving the problems of control and taking charge of our future. But there is also no law that mandates it. AI is proving at an exponential rate. And there are exactly two times to react to an exponential too early or too late. Whether we take control of our machines or our machines take control of us is not yet decided, but it will be decided soon. Thank you. You. It's.
