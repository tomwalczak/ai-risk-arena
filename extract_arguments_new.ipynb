{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f418b28d-060a-4e1c-b804-d76264ca0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (1.4.47)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (0.5.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (0.0.21)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.24 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (0.1.25)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (0.1.5)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.1.8) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.8) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.8) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.8) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.8) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.8) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.8) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.8) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.8) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.8) (0.8.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.8) (2.3)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.2,>=0.1.24->langchain==0.1.8) (3.6.2)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.2,>=0.1.24->langchain==0.1.8) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.8) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain==0.1.8) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain==0.1.8) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain==0.1.8) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.8) (2.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.24->langchain==0.1.8) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.8) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "DEPRECATION: dropbox 11.36.0 has a non-standard dependency specifier stone>=2.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of dropbox or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai==0.0.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.6)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openai==0.0.6) (0.1.25)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openai==0.0.6) (1.23.5)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openai==0.0.6) (1.12.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-openai==0.0.6) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (6.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (3.6.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (0.1.5)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (8.2.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.6) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.6) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.6) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.6) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.6) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.6) (2023.3.23)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (2.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.6) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.6) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.6) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (2.0.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai==0.0.6) (1.26.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai==0.0.6) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "DEPRECATION: dropbox 11.36.0 has a non-standard dependency specifier stone>=2.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of dropbox or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv==1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "DEPRECATION: dropbox 11.36.0 has a non-standard dependency specifier stone>=2.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of dropbox or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb==0.4.18 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.18)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (1.10.7)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (0.95.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.18) (0.22.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (4.9.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (1.15.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (1.21.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (0.13.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (1.59.3)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (4.0.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (28.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (6.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.4.18) (1.23.5)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi>=0.95.2->chromadb==0.4.18) (0.27.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.18) (2022.12.7)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.18) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.18) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.18) (2.23.4)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.18) (1.5.1)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.18) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.18) (3.2.2)\n",
      "Requirement already satisfied: urllib3<2.0,>=1.24.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==0.4.18) (1.26.15)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.18) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.18) (23.5.26)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.18) (23.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.18) (4.23.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.4.18) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.18) (1.2.13)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.18) (6.6.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.18) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.18) (1.61.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.18) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.18) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.42b0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.18) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.42b0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.18) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.18) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.42b0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.18) (0.42b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.18) (67.8.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.18) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.18) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.4.18) (1.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.28->chromadb==0.4.18) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.28->chromadb==0.4.18) (2.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.65.0->chromadb==0.4.18) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer>=0.9.0->chromadb==0.4.18) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.18) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.18) (0.5.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.18) (1.0.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.18) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.18) (12.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.18) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.18) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.18) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.4.18) (3.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.95.2->chromadb==0.4.18) (3.6.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.18) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.18) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.95.2->chromadb==0.4.18) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.18) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.18) (0.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "DEPRECATION: dropbox 11.36.0 has a non-standard dependency specifier stone>=2.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of dropbox or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.8\n",
    "!pip install langchain-openai==0.0.6\n",
    "!pip install python-dotenv==1.0.0\n",
    "!pip install chromadb==0.4.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98356761-e795-4338-9aef-8d05b212388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106d34e5-61c0-4667-81ea-18bd8437d645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7dbba34-6940-430b-8057-419f77abf163",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\",\n",
    "                 temperature=0.7,\n",
    "                 model_kwargs={\n",
    "                    \"frequency_penalty\": 0.0,\n",
    "                     \"presence_penalty\": 0.0,\n",
    "                     \"top_p\": 1.0,\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729fece9-860b-4fd9-9e40-10f2962026bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(filename, text):\n",
    "    try:\n",
    "        directory = os.path.dirname(filename)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        with open(filename, 'a') as file:\n",
    "            file.write(text)\n",
    "        print(\"Text successfully written to\", filename)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd30f70b-2af9-4a99-8018-f7ebbe34108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_json(data, filename):\n",
    "    directory = os.path.dirname(filename)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78957f9-1683-4c12-ac90-136b14419ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results_from_json(int):\n",
    "    if int == 1:\n",
    "        with open(\"./sources/json/first_cycle_results.json\", 'r') as file:\n",
    "            data = json.load(file)\n",
    "            return data\n",
    "    if int == 2:\n",
    "        with open(\"./sources/json/second_cycle_results.json\", 'r') as file:\n",
    "            data = json.load(file)\n",
    "            return data\n",
    "    if int == 3:\n",
    "        with open(\"./sources/json/third_cycle_results.json\", 'r') as file:\n",
    "            data = json.load(file)\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8360efe1-f307-466d-aa59-312cf30f0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cycle_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"\"\"\n",
    "    Read the following transcript and extract all the arguments made about AI safety. Make sure they are self-contained.\n",
    "\n",
    "  You must stick as close as possible to the transcript - use the author's own words and tone of voice.\n",
    "\n",
    "  You must write each argument in a valid YAML format, surrounded with backticks.\n",
    "  You must separate each argument with a new line.\n",
    "\n",
    "\n",
    "  The simplest possible argument must at least contain three claims:\n",
    "\n",
    "  ```yaml\n",
    "  claim: \"Top-level claim\"\n",
    "  premises:\n",
    "    - claim: \"First independent premise supporting the top-level claim\"\n",
    "    - claim: \"Second independent premise supporting the top-level claim\"\n",
    "  ```\n",
    "\n",
    "  And here's an example of a more complex argument, which also includes examples to illustrate lower-level claims:\n",
    "\n",
    "  ```yaml\n",
    "  claim: \"Top-level claim\"\n",
    "  premises:\n",
    "    - claim: \"First independent premise supporting the top-level claim\"\n",
    "    - claim: \"Supporting premise for the top-level claim\"\n",
    "      example: \"Example supporting this premise\"\n",
    "    - claim: \"Another supporting premise for the top-level claim\"\n",
    "    - claim: \"Second independent premise supporting the top-level claim\"\n",
    "      premises:\n",
    "        - claim: \"Supporting premise for the second independent premise\"\n",
    "        - claim: \"Another supporting premise for the second independent premise\"\n",
    "        - claim: \"Independent premise supporting the second independent premise\"\n",
    "          example: \"Example supporting this independent premise\"\n",
    "  ```\n",
    "\n",
    "  Here's how to read this structure:\n",
    "\n",
    "  The top-level claim is the main argument.\n",
    "  Directly nested under the claim are independent premises. These provide justification independently of other premises.\n",
    "  An example can be nested directly under a claim to provide further context or support.\n",
    "  Just like the top-level claim, each premise can itself be supported by further individual premises, or examples, creating a nested structure.\n",
    "\n",
    "  # Here is the transcript:\n",
    "\n",
    "  {transcript}\n",
    "  \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ae46fd-4e4d-4780-9b11-f839d2a02e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cycle_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"\"\"\n",
    "  Based on the following transcript, make the arguments clear and distinct. \n",
    "  You may need to merge similar arguments to create a better, more logical argument.\n",
    "\n",
    "  Create the best, strongest possible version of the arguments, here's what to do:\n",
    "\n",
    "  - Make sure the arguments is self-contained\n",
    "  - Make the arguments understandable on their own, out-of-context\n",
    "  - Remember, arguments are not a description or an explanation\n",
    "  - Premise must always give a reason to believe the claim above\n",
    "  - Avoid using pronouns in premises\n",
    "  - A claim can have a maximum of two child claims (premises), rewrite if needed\n",
    "\n",
    "  # Argument format \n",
    "\n",
    "  You must write each argument in valid YAML format, surrounded with backticks.\n",
    "  Separate each argument with new line.\n",
    "  You must stick as closely as possible to the transcript. \n",
    "  Above all, you must express the argument in the words of the author, stick as close as possible to the tone of voice and phrases used in the transcript.\n",
    "\n",
    "\n",
    "\n",
    "  Here are some examples:\n",
    "\n",
    "  A simple argument might look like this: \n",
    "\n",
    "  ```yaml\n",
    "  claim: \"Top-level claim\"\n",
    "  premises:\n",
    "    - claim: \"First independent premise supporting the top-level claim\"\n",
    "    - claim: \"Second independent premise supporting the top-level claim\"\n",
    "  ```\n",
    "\n",
    "  And here's an example of a more complex argument, which also includes examples to illustrate lower-level claims:\n",
    "\n",
    "  ```yaml\n",
    "  claim: \"Top-level claim\"\n",
    "  premises:\n",
    "    - claim: \"First independent premise supporting the top-level claim\"\n",
    "    - claim: \"Supporting premise for the top-level claim\"\n",
    "      example: \"Example supporting this premise\"\n",
    "    - claim: \"Another supporting premise for the top-level claim\"\n",
    "    - claim: \"Second independent premise supporting the top-level claim\"\n",
    "      premises:\n",
    "        - claim: \"Supporting premise for the second independent premise\"\n",
    "        - claim: \"Another supporting premise for the second independent premise\"\n",
    "        - claim: \"Independent premise supporting the second independent premise\"\n",
    "          example: \"Example supporting this independent premise\"\n",
    "  ```\n",
    "\n",
    "  Here's how to read this structure:\n",
    "\n",
    "  The top-level claim is the main argument.\n",
    "  Directly nested under the claim are independent premises. These provide justification independently of other premises.\n",
    "  An example can be nested directly under a claim to provide further context or support.\n",
    "  Just like the top-level claim, each premise can itself be supported by further individual premises, or examples, creating a nested structure.\n",
    "\n",
    "\n",
    "  # Arguments to improve:\n",
    "\n",
    "  {all_arguments}\n",
    "\n",
    "  # Transcript\n",
    "\n",
    "  {transcript}\n",
    "  \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa75b11-6b3b-493c-8c32-01ef58a562cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_cycle_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world expert at creating accessible, persuasive explanations.\"),\n",
    "    (\"user\", \"\"\"\n",
    "  Based on your own knowledge and the transcript, create a structured explanation for the following argument. Use the context from the transcript for the explanation.\n",
    "\n",
    "  # Argument to use for the explanation\n",
    "\n",
    "  {argument}\n",
    "\n",
    "\n",
    "  The structured explanation must be directly based on the argument. You can also use the provided transcript for context.\n",
    "\n",
    "  You must follow this YAML format:\n",
    "\n",
    "  ```yaml\n",
    "  counteragument_to: (what would be the argument, to which this argument is a counterargument? use your own knowledge. use bullet points)\n",
    "\n",
    "  strongest_objection: (what is the strongest, good-faith, honest objection that a thoughful person might have? use bullet points)\n",
    "  consequences_if_true: (if true, what would be the consequences? write in causal language,  use bullet points, max 3)\n",
    "\n",
    "  link_to_ai_safety: (how is this linked to AI safety? 1 sentence.)\n",
    "\n",
    "  simple_explanation: (explain this clearly to a college student in max. 4 sentences, speak persuasively as the author of this argument. don't use bullet points)\n",
    "\n",
    "  examples: (max 3 examples, use bullet points)\n",
    "\n",
    "  ```\n",
    "\n",
    "  # Here is the transcript:\n",
    "\n",
    "  {transcript}\n",
    "  \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "274af6ed-0d16-4e5b-ae57-868d7418efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_from_sources_and_make_chunks(directory):\n",
    "    folder_names = []\n",
    "    raw_texts = []\n",
    "    for entry in os.listdir(directory):\n",
    "        folder_names.append(entry)\n",
    "        print(folder_names)\n",
    "    for folder_name in folder_names:\n",
    "        loader = DirectoryLoader(f'./sources/{folder_name}/source', glob=\"**/*.md\")\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=10000,\n",
    "        chunk_overlap=0,\n",
    "        length_function=len)\n",
    "        raw_text = loader.load()\n",
    "        entire_text_from_a_source = \"\"\n",
    "        for doc in raw_text:\n",
    "            entire_text_from_a_source += doc.page_content\n",
    "        chunks = text_splitter.create_documents([entire_text_from_a_source])\n",
    "        formatted_chunks = []\n",
    "        for chunk in chunks:\n",
    "            formatted_chunks.append(chunk.page_content)\n",
    "        temp = {\n",
    "            \"name\" : folder_name,\n",
    "            \"path\": f'./sources/{folder_name}',\n",
    "            \"chunks\": formatted_chunks,\n",
    "        }\n",
    "        raw_texts.append(temp)\n",
    "    return raw_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cffef20-d5b3-474c-995c-636f00c05cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['harary-mar-4-001']\n"
     ]
    }
   ],
   "source": [
    "sources_dicts = load_text_from_sources_and_make_chunks(\"./sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bafcb6e1-e0fb-41bd-8469-b463d105ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_cycle_of_extracting_arguments(dicts):\n",
    "    first_cycle_chain = first_cycle_prompt | llm\n",
    "    for dict in dicts:\n",
    "        dict[\"arguments\"] = []\n",
    "        for chunk in dict[\"chunks\"]:\n",
    "            first_cycle_response = first_cycle_chain.invoke({\"transcript\": chunk})\n",
    "            dict[\"arguments\"].append(first_cycle_response.content)\n",
    "        print(\"over\")\n",
    "        text = '\\n\\n'.join(dict[\"arguments\"])\n",
    "        filename = f\"{dict['path']}/steps/first_step.md\"\n",
    "        write_to_file(filename, text)\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16983b7e-dc71-418e-b5e4-f340b1846e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n",
      "Text successfully written to ./sources/harary-mar-4-001/steps/first_step.md\n"
     ]
    }
   ],
   "source": [
    "dicts_with_extracted_args = first_cycle_of_extracting_arguments(sources_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d0d68af-6a24-40fd-aa63-7ae2cdfb0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_json(dicts_with_extracted_args, \"./sources/json/first_cycle_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2acb9d74-4988-4f3e-9cb3-9a53956ec7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_cycle_of_extracting_arguments(dicts):\n",
    "    second_cycle_chain = second_cycle_prompt | llm\n",
    "    for dict in dicts:\n",
    "        dict[\"improved_arguments\"] = []\n",
    "        for i, chunk in enumerate(dict[\"chunks\"]):\n",
    "            second_cycle_response = second_cycle_chain.invoke({\"all_arguments\": dict[\"arguments\"][i], \"transcript\": chunk })\n",
    "            dict[\"improved_arguments\"].append(second_cycle_response.content)\n",
    "        print(\"over\")\n",
    "        text = '\\n\\n'.join(dict[\"improved_arguments\"])\n",
    "        filename = f\"{dict['path']}/steps/second_step.md\"\n",
    "        write_to_file(filename, text)\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b45be49-f2ce-4e39-95e4-bd7ed762809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n",
      "Text successfully written to ./sources/harary-mar-4-001/steps/second_step.md\n"
     ]
    }
   ],
   "source": [
    "dicts_with_extracted_and_improved_args = second_cycle_of_extracting_arguments(dicts_with_extracted_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41ae0410-b3c8-4c53-8451-8dbe915c6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_improved_arguments_in_dict(dicts):\n",
    "    for dict in dicts:\n",
    "        dict[\"isolated_arguments\"] = []\n",
    "        for improved_arg in dict[\"improved_arguments\"]:\n",
    "            if improved_arg:\n",
    "                splitted_args = improved_arg.split(\"```yaml\")\n",
    "                splitted_args_cleaned = []\n",
    "                for arg in splitted_args:\n",
    "                    arg_clean = arg.split(\"```\")[0]\n",
    "                    if (arg_clean != \"\"):\n",
    "                        splitted_args_cleaned.append(arg_clean.strip())   \n",
    "                if splitted_args_cleaned != None:\n",
    "                    dict[\"isolated_arguments\"].append(splitted_args_cleaned)\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6176109-6d8a-4e58-861b-e8707aeb0b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_with_isolated_improved_arguments = split_improved_arguments_in_dict(dicts_with_extracted_and_improved_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a1eec61-b2d6-43c5-bde6-26e2bcbd1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_json(dicts_with_isolated_improved_arguments, \"./sources/json/second_cycle_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bbb2a99-f23f-4c28-9812-386bdf73ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_with_smaller_chunks(directory):\n",
    "    folder_names = []\n",
    "    all_chunks = []\n",
    "    dbs = []\n",
    "    for entry in os.listdir(directory):\n",
    "        if entry != \"json\":\n",
    "            folder_names.append(entry)\n",
    "    for folder_name in folder_names:\n",
    "        loader = DirectoryLoader(f'./sources/{folder_name}/source', glob=\"**/*.md\")\n",
    "        text_splitter = TokenTextSplitter(chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len)\n",
    "        raw_text = loader.load()\n",
    "        entire_text_from_a_source = \"\"\n",
    "        for doc in raw_text:\n",
    "            entire_text_from_a_source += doc.page_content\n",
    "        chunks = text_splitter.create_documents([entire_text_from_a_source])\n",
    "        for chunk in chunks:\n",
    "            chunk.metadata = {\"folder\": folder_name}\n",
    "            all_chunks.append(chunk)\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "        db = Chroma.from_documents(all_chunks, embeddings)\n",
    "        dbs.append(db)\n",
    "    return dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71a58393-7906-47ea-8070-6082914bf81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = create_embeddings_with_smaller_chunks(\"./sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2a48a0d-bf72-40fb-85f9-5033db492991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_cycle_of_extracting_arguments(dicts):\n",
    "    third_cycle_chain = third_cycle_prompt | llm\n",
    "    for i, dict in enumerate(dicts):\n",
    "        dict[\"explanations\"] = []\n",
    "        db = dbs[i]\n",
    "        for i, chunk in enumerate(dict[\"chunks\"]):\n",
    "            explanations = []\n",
    "            for arg in dict[\"isolated_arguments\"][i]:\n",
    "                docs = db.similarity_search(arg, k=3)\n",
    "                print(docs)\n",
    "                context = \"\"\n",
    "                for doc in docs:\n",
    "                    context += \"\\n\" + doc.page_content\n",
    "                explanation = third_cycle_chain.invoke({\"argument\": arg, \"transcript\": context})\n",
    "                explanations.append(explanation.content.split(\"```yaml\\n\")[1].split(\"```\")[0].strip())\n",
    "            dict[\"explanations\"].append(explanations)\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5de267f-8b42-48fa-8ad5-a5a5341d60fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Hello, everybody. Thank you for this wonderful introduction. And yes, what I want to talk to you about is AI and the future of humanity. Now, I know that this conference is focused on the ecological crisis facing humanity. But for better or for worse, AI, too, is part of this crisis. AI can help us in many ways to overcome the ecological crisis, or it can make it far, far worse. The Emergence Of Inorganic Agents Actually, AI will probably change the very meaning of the ecological system. Because for four billion years, the ecological system of planet Earth contained only organic life forms. And now, or soon, we might see the emergence of the first inorganic life forms, so four billion years, or at the very least, the emergence of inorganic agents. Now, people have feared AI since the very beginning of the computer age, in the middle of the 20th century. And this fear has inspired many science fiction classics, like The Terminator or The Matrix. Now, while such science fiction scenarios have become cultural landmarks, they haven’t usually been taken seriously in academic and scientific and political debate, and perhaps for a good reason. Because science fiction scenarios usually assume that before AI can pose a significant threat to humanity, it will have to reach or to pass two important milestones. First, AI will have to become sentient and develop consciousness, feelings, emotions. Otherwise, why would it even want to take over the world? Secondly, AI will have to become adept at navigating the physical world. Robots will have to be able to move around and operate in houses and cities and mountains and forests, at least as dexterously and efficiently as humans. If they cannot move around the physical world, how can they possibly take it over? And as of April 2023, AI still seems far from reaching either of these milestones. Despite all the hype around ChatGPT and the other new AI tools, there is no evidence that these tools have even a shred of consciousness, of feelings, of emotions. As for navigating the physical world, despite the hype around self-driving vehicles, the date at which these vehicles will dominate our roads keeps being postponed. However, the bad news is that to threaten the survival of human civilization, AI doesn’t really need consciousness and it doesn’t need the ability to move around the physical world. Over the last few years, new AI tools have been unleashed into the public sphere, which may threaten the survival of human civilization from a very unexpected direction. And it’s difficult for us to even grasp the capabilities of these new AI tools and the speed at which they continue to develop. Fundamental Abilities Of The New AI Tools Indeed, because AI is able to learn by itself, to improve itself, even the developers of these tools don’t know the full capabilities of what they have created and they are themselves often surprised by emergent abilities and emergent qualities of these tools. I guess everybody here is already aware of some of the most fundamental abilities of the new AI tools, abilities like writing text, drawing images, composing music, and writing code. But there are many additional capabilities that are emerging, like deepfaking people’s voices and images, like drafting bills, finding weaknesses both in computer code and also in legal contracts and in legal agreements. But perhaps most importantly, the new AI tools are gaining the ability to develop deep and intimate relationships with human beings. Each of these abilities deserves an entire discussion, and it is difficult for us to understand their full implications. So let’s make it simple. When we take all of these abilities together as a package, they boil down to one very, very big thing: The ability to manipulate and to generate language, whether with words or images or sounds. The most important aspect of the current state of the ongoing AI revolution is that AI is gaining mastery of language at a level that surpasses the average human ability. And by gaining mastery of language, AI is seizing the master key, unlocking the doors of all our institutions, from banks to temples. Because language is the tool that we use to give instructions to our bank and also to inspire heavenly visions in our minds. Another way to think of it is that AI has just hacked the operating system of human civilization. The operating system of every human culture in history has always been language. In The Beginning Was The Word. We use language to create mythology and laws, to create gods and money, to create art and science, to create friendships and nations. For example, human rights are not a biological reality. They are not inscribed in our DNA. Human rights is something that we created with language by telling stories and writing laws. Gods are also not a biological or physical reality. Gods too is something that we humans have created with language by telling legends and writing scriptures. Money is not a biological or physical reality. Banknotes are just worthless pieces of paper, and', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by gaining mastery of human language, AI has all it needs in order to cocoon us in a Matrix-like world of illusion. Contrary to what some conspiracy theories assume, you don’t really need to implant chips in people’s brains in order to control them, or to manipulate them. For thousands of years, prophets and poets and politicians have used language and storytelling in order to manipulate and to control people and to reshape society. Now, AI is likely to be able to do it. And once it can do that, it doesn’t need to send killer robots to shoot us. It can get humans to pull the trigger if it really needs to. Fear of AI Revolution Now, fear of AI has haunted humankind for only the last few generations, let’s say from the middle of the 20th century. If you go back to Frankenstein, maybe it’s 200 years. But for thousands of years, humans have been haunted by a much, much deeper fear. Humans have always appreciated the power of stories and images and language to manipulate our minds and to create illusions. Consequently, since ancient times, humans feared being trapped in a world of illusions. In the 17th century, René Descartes feared that perhaps a malicious demon was trapping him inside this kind of world of illusions, creating everything that Descartes saw and heard. In ancient Greece, Plato told the famous allegory of the cave, in which a group of people is chained inside a cave all their lives, facing a blank wall, a screen. On that screen, they see projected various shadows, and the prisoners mistake these illusions, these shadows, for the reality. In ancient India, Buddhist and Hindu sages pointed out that all humans lived trapped inside what they called Maya. Maya is the world of illusions. Buddha said that what we normally take to be reality is often just fiction in our own minds. People may wage entire wars, killing others and being willing to be killed themselves because of their belief in this fiction. So the AI revolution is bringing us face to face with Descartes’ demon, with Plato’s cave, with the Maya. If we are not careful, a curtain of illusions could descend over the whole of humankind, and we will never be able to tear that curtain away, or even realize that it is there, because we’ll think this is reality. Social Media and AI And social media, if this sounds far-fetched, so just look at social media over the last few years. Social media has given us a small taste of things to come. In social media, primitive AI tools, but very primitive, have been used not to create content, but to curate content which is produced by human beings. The humans produce stories and videos and whatever, and the AI chooses which stories, which videos would reach our ears and eyes, selecting those that will get the most attention, that will be the most viral. And while very primitive, these AI tools have nevertheless been sufficient to create this kind of curtain of illusions that increase societal polarization all over the world, undermine our mental health, and destabilize democratic societies. Millions of people have confused these illusions for the reality. The USA has the most powerful information technology in the whole of history, and yet American citizens can no longer agree who won the last election, or whether climate change is real, or whether vaccines prevent illnesses or not. The new AI tools are far, far more powerful than these social media algorithms, and they could cause far more damage. Now, of course, AI has enormous positive potential too. I didn’t talk about it because the people who develop AI naturally talk about it enough. You don’t need me to add up to that cause. Positive Potential of AI The job of historians and philosophers like myself is often to point out the dangers. But certainly, AI can help us in countless ways, from finding new cures to cancer to discovering solutions to the ecological crisis that we are facing. In order to make sure that the new AI tools are used for good and not for ill, we first need to appreciate their true capabilities, and we need to regulate them very, very carefully. Since 1945, we knew that nuclear technology could physically destroy human civilization, as well as benefiting us by producing cheap and plentiful energy. We therefore reshaped the entire international order to protect ourselves and to make sure that nuclear technology is used primarily for', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' The really interesting thing was his willingness to risk and ultimately lose his very lucrative job for the sake of the AI chatbot that he thought he was protecting. If AI can influence people to risk and lose their jobs, what else can it induce us to do? In every political battle, for hearts and minds, intimacy is the most effective weapon of all, and AI has just gained the ability to mass-produce intimacy with millions, hundreds of millions of people. Now, as you probably all know, over the past decade, social media has become a battlefield for controlling human attention. Now, with the new generation of AI, the battlefront is shifting from attention to intimacy, and this is very bad news. What will happen to human society and to human psychology as AI fights AI in a battle to create intimate relationships with us, relationships that can then be used to convince us to buy particular products or to vote for particular politicians? Even without creating fake intimacy, the new AI tools would have an immense influence on human opinions and on our worldview. People, for instance, may come to use, are already coming to use, a single AI advisor as a one-stop oracle and as the source for all the information they need. No wonder that Google is terrified. If you’ve been watching the news lately, Google is terrified, and for a good reason. Why bother searching yourself when you can just ask the oracle to tell you anything you want? You don’t need to search. The news industry and the advertisement industry should also be terrified. Why read a newspaper when I can just ask the oracle to tell me what’s new? And what’s the point, what’s the purpose of advertisement when I can just ask the oracle to tell me what to buy? So there is a chance that within a very short time the entire advertisement industry will collapse, while AI, or the people and companies that control the new AI oracles, will become extremely, extremely powerful. What we are potentially talking about is nothing less than the end of human history. Now, not the end of history, just the end of the human-dominated part of what we call history. History is the interaction between biology and culture. It’s the interaction between our biological needs and desires for things like food and sex, and our cultural creations like religions and laws. History is the process through which religions and laws interact with food and sex. When AI Takes Over Culture Now, what will happen to the cause of this interaction of history when AI takes over culture? Within a few years, AI could eat the whole of human culture, everything we’ve produced for thousands and thousands of years, digest it, and start gushing out a flood of new cultural creations, new cultural artifacts. And remember that we humans, we never really have direct access to reality. We are always cocooned by culture, and we always experience reality through a cultural prism. Our political views are shaped by the stories of journalists and by the anecdotes of friends. Our sexual preferences are tweaked by movies and fairy tales. Even the way that we walk and breathe is subtly nudged by cultural traditions. Previously, this cultural cocoon was always woven by other human beings. Previous tools, like printing presses, radios, or televisions, helped to spread the cultural ideas and creations of humans, but they could never create something new by themselves. A printing press cannot create a new book. It’s always done by a human. AI is fundamentally different from printing presses, from radios, from every previous invention in history, because it can create completely new ideas. It can create a new culture. And the big question is, what will it be like to experience reality through a prism produced by a non-human intelligence, by an alien intelligence? Now at first, in the first few years, AI will probably largely imitate the human prototype that fed it in its infancy. But with each passing year, AI culture will boldly go where no human has gone before. So for thousands of years, we humans basically lived inside the dreams and fantasies of other humans. We have worshipped gods, we pursued ideals of beauty, we dedicated our lives to causes that originated in the imagination of some human poet or prophet or politician. Soon, we might find ourselves living inside the dreams and fantasies of an alien intelligence. And the danger that this poses, or the potential danger, it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by', metadata={'folder': 'harary-mar-4-001'})]\n",
      "[Document(page_content='Hello, everybody. Thank you for this wonderful introduction. And yes, what I want to talk to you about is AI and the future of humanity. Now, I know that this conference is focused on the ecological crisis facing humanity. But for better or for worse, AI, too, is part of this crisis. AI can help us in many ways to overcome the ecological crisis, or it can make it far, far worse. The Emergence Of Inorganic Agents Actually, AI will probably change the very meaning of the ecological system. Because for four billion years, the ecological system of planet Earth contained only organic life forms. And now, or soon, we might see the emergence of the first inorganic life forms, so four billion years, or at the very least, the emergence of inorganic agents. Now, people have feared AI since the very beginning of the computer age, in the middle of the 20th century. And this fear has inspired many science fiction classics, like The Terminator or The Matrix. Now, while such science fiction scenarios have become cultural landmarks, they haven’t usually been taken seriously in academic and scientific and political debate, and perhaps for a good reason. Because science fiction scenarios usually assume that before AI can pose a significant threat to humanity, it will have to reach or to pass two important milestones. First, AI will have to become sentient and develop consciousness, feelings, emotions. Otherwise, why would it even want to take over the world? Secondly, AI will have to become adept at navigating the physical world. Robots will have to be able to move around and operate in houses and cities and mountains and forests, at least as dexterously and efficiently as humans. If they cannot move around the physical world, how can they possibly take it over? And as of April 2023, AI still seems far from reaching either of these milestones. Despite all the hype around ChatGPT and the other new AI tools, there is no evidence that these tools have even a shred of consciousness, of feelings, of emotions. As for navigating the physical world, despite the hype around self-driving vehicles, the date at which these vehicles will dominate our roads keeps being postponed. However, the bad news is that to threaten the survival of human civilization, AI doesn’t really need consciousness and it doesn’t need the ability to move around the physical world. Over the last few years, new AI tools have been unleashed into the public sphere, which may threaten the survival of human civilization from a very unexpected direction. And it’s difficult for us to even grasp the capabilities of these new AI tools and the speed at which they continue to develop. Fundamental Abilities Of The New AI Tools Indeed, because AI is able to learn by itself, to improve itself, even the developers of these tools don’t know the full capabilities of what they have created and they are themselves often surprised by emergent abilities and emergent qualities of these tools. I guess everybody here is already aware of some of the most fundamental abilities of the new AI tools, abilities like writing text, drawing images, composing music, and writing code. But there are many additional capabilities that are emerging, like deepfaking people’s voices and images, like drafting bills, finding weaknesses both in computer code and also in legal contracts and in legal agreements. But perhaps most importantly, the new AI tools are gaining the ability to develop deep and intimate relationships with human beings. Each of these abilities deserves an entire discussion, and it is difficult for us to understand their full implications. So let’s make it simple. When we take all of these abilities together as a package, they boil down to one very, very big thing: The ability to manipulate and to generate language, whether with words or images or sounds. The most important aspect of the current state of the ongoing AI revolution is that AI is gaining mastery of language at a level that surpasses the average human ability. And by gaining mastery of language, AI is seizing the master key, unlocking the doors of all our institutions, from banks to temples. Because language is the tool that we use to give instructions to our bank and also to inspire heavenly visions in our minds. Another way to think of it is that AI has just hacked the operating system of human civilization. The operating system of every human culture in history has always been language. In The Beginning Was The Word. We use language to create mythology and laws, to create gods and money, to create art and science, to create friendships and nations. For example, human rights are not a biological reality. They are not inscribed in our DNA. Human rights is something that we created with language by telling stories and writing laws. Gods are also not a biological or physical reality. Gods too is something that we humans have created with language by telling legends and writing scriptures. Money is not a biological or physical reality. Banknotes are just worthless pieces of paper, and', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by gaining mastery of human language, AI has all it needs in order to cocoon us in a Matrix-like world of illusion. Contrary to what some conspiracy theories assume, you don’t really need to implant chips in people’s brains in order to control them, or to manipulate them. For thousands of years, prophets and poets and politicians have used language and storytelling in order to manipulate and to control people and to reshape society. Now, AI is likely to be able to do it. And once it can do that, it doesn’t need to send killer robots to shoot us. It can get humans to pull the trigger if it really needs to. Fear of AI Revolution Now, fear of AI has haunted humankind for only the last few generations, let’s say from the middle of the 20th century. If you go back to Frankenstein, maybe it’s 200 years. But for thousands of years, humans have been haunted by a much, much deeper fear. Humans have always appreciated the power of stories and images and language to manipulate our minds and to create illusions. Consequently, since ancient times, humans feared being trapped in a world of illusions. In the 17th century, René Descartes feared that perhaps a malicious demon was trapping him inside this kind of world of illusions, creating everything that Descartes saw and heard. In ancient Greece, Plato told the famous allegory of the cave, in which a group of people is chained inside a cave all their lives, facing a blank wall, a screen. On that screen, they see projected various shadows, and the prisoners mistake these illusions, these shadows, for the reality. In ancient India, Buddhist and Hindu sages pointed out that all humans lived trapped inside what they called Maya. Maya is the world of illusions. Buddha said that what we normally take to be reality is often just fiction in our own minds. People may wage entire wars, killing others and being willing to be killed themselves because of their belief in this fiction. So the AI revolution is bringing us face to face with Descartes’ demon, with Plato’s cave, with the Maya. If we are not careful, a curtain of illusions could descend over the whole of humankind, and we will never be able to tear that curtain away, or even realize that it is there, because we’ll think this is reality. Social Media and AI And social media, if this sounds far-fetched, so just look at social media over the last few years. Social media has given us a small taste of things to come. In social media, primitive AI tools, but very primitive, have been used not to create content, but to curate content which is produced by human beings. The humans produce stories and videos and whatever, and the AI chooses which stories, which videos would reach our ears and eyes, selecting those that will get the most attention, that will be the most viral. And while very primitive, these AI tools have nevertheless been sufficient to create this kind of curtain of illusions that increase societal polarization all over the world, undermine our mental health, and destabilize democratic societies. Millions of people have confused these illusions for the reality. The USA has the most powerful information technology in the whole of history, and yet American citizens can no longer agree who won the last election, or whether climate change is real, or whether vaccines prevent illnesses or not. The new AI tools are far, far more powerful than these social media algorithms, and they could cause far more damage. Now, of course, AI has enormous positive potential too. I didn’t talk about it because the people who develop AI naturally talk about it enough. You don’t need me to add up to that cause. Positive Potential of AI The job of historians and philosophers like myself is often to point out the dangers. But certainly, AI can help us in countless ways, from finding new cures to cancer to discovering solutions to the ecological crisis that we are facing. In order to make sure that the new AI tools are used for good and not for ill, we first need to appreciate their true capabilities, and we need to regulate them very, very carefully. Since 1945, we knew that nuclear technology could physically destroy human civilization, as well as benefiting us by producing cheap and plentiful energy. We therefore reshaped the entire international order to protect ourselves and to make sure that nuclear technology is used primarily for', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' The really interesting thing was his willingness to risk and ultimately lose his very lucrative job for the sake of the AI chatbot that he thought he was protecting. If AI can influence people to risk and lose their jobs, what else can it induce us to do? In every political battle, for hearts and minds, intimacy is the most effective weapon of all, and AI has just gained the ability to mass-produce intimacy with millions, hundreds of millions of people. Now, as you probably all know, over the past decade, social media has become a battlefield for controlling human attention. Now, with the new generation of AI, the battlefront is shifting from attention to intimacy, and this is very bad news. What will happen to human society and to human psychology as AI fights AI in a battle to create intimate relationships with us, relationships that can then be used to convince us to buy particular products or to vote for particular politicians? Even without creating fake intimacy, the new AI tools would have an immense influence on human opinions and on our worldview. People, for instance, may come to use, are already coming to use, a single AI advisor as a one-stop oracle and as the source for all the information they need. No wonder that Google is terrified. If you’ve been watching the news lately, Google is terrified, and for a good reason. Why bother searching yourself when you can just ask the oracle to tell you anything you want? You don’t need to search. The news industry and the advertisement industry should also be terrified. Why read a newspaper when I can just ask the oracle to tell me what’s new? And what’s the point, what’s the purpose of advertisement when I can just ask the oracle to tell me what to buy? So there is a chance that within a very short time the entire advertisement industry will collapse, while AI, or the people and companies that control the new AI oracles, will become extremely, extremely powerful. What we are potentially talking about is nothing less than the end of human history. Now, not the end of history, just the end of the human-dominated part of what we call history. History is the interaction between biology and culture. It’s the interaction between our biological needs and desires for things like food and sex, and our cultural creations like religions and laws. History is the process through which religions and laws interact with food and sex. When AI Takes Over Culture Now, what will happen to the cause of this interaction of history when AI takes over culture? Within a few years, AI could eat the whole of human culture, everything we’ve produced for thousands and thousands of years, digest it, and start gushing out a flood of new cultural creations, new cultural artifacts. And remember that we humans, we never really have direct access to reality. We are always cocooned by culture, and we always experience reality through a cultural prism. Our political views are shaped by the stories of journalists and by the anecdotes of friends. Our sexual preferences are tweaked by movies and fairy tales. Even the way that we walk and breathe is subtly nudged by cultural traditions. Previously, this cultural cocoon was always woven by other human beings. Previous tools, like printing presses, radios, or televisions, helped to spread the cultural ideas and creations of humans, but they could never create something new by themselves. A printing press cannot create a new book. It’s always done by a human. AI is fundamentally different from printing presses, from radios, from every previous invention in history, because it can create completely new ideas. It can create a new culture. And the big question is, what will it be like to experience reality through a prism produced by a non-human intelligence, by an alien intelligence? Now at first, in the first few years, AI will probably largely imitate the human prototype that fed it in its infancy. But with each passing year, AI culture will boldly go where no human has gone before. So for thousands of years, we humans basically lived inside the dreams and fantasies of other humans. We have worshipped gods, we pursued ideals of beauty, we dedicated our lives to causes that originated in the imagination of some human poet or prophet or politician. Soon, we might find ourselves living inside the dreams and fantasies of an alien intelligence. And the danger that this poses, or the potential danger, it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by', metadata={'folder': 'harary-mar-4-001'})]\n",
      "[Document(page_content=' cancer to discovering solutions to the ecological crisis that we are facing. In order to make sure that the new AI tools are used for good and not for ill, we first need to appreciate their true capabilities, and we need to regulate them very, very carefully. Since 1945, we knew that nuclear technology could physically destroy human civilization, as well as benefiting us by producing cheap and plentiful energy. We therefore reshaped the entire international order to protect ourselves and to make sure that nuclear technology is used primarily for good. We now have to grapple with a new weapon of mass destruction that can annihilate our mental and social world. One big difference between nukes and AI is that nukes cannot produce more powerful nukes. AI can produce more powerful AI, so we need to act quickly before AI gets out of our control. Drug companies cannot sell people new medicines without first subjecting these products to rigorous safety checks. Biotech labs cannot just release a new virus into the public sphere in order to impress their shareholders with their technological wizardry. Similarly, governments must immediately ban the release into the public domain of any more revolutionary AI tools before they are made safe. Again, I’m not talking about stopping all research in AI. The first step is to stop the release into the public sphere. You can research viruses without releasing them to the public. You can research AI, but don’t release them too quickly into the public domain. AI Arms Race If we don’t slow down the AI arms race, we will not have time to even understand what is happening, let alone to regulate effectively this incredibly powerful technology. You might be wondering or asking, won’t slowing down the public deployment of AI cause democracies to lag behind more ruthless authoritarian regimes? The answer is absolutely no. Exactly the opposite. Unregulated AI deployment is what will cause democracies to lose to dictatorships. Because if we unleash chaos, authoritarian regimes could more easily contain this chaos than could open societies. Democracy, in essence, is a conversation. Democracy is an open conversation. Dictatorship is a dictate. There is one person dictating everything, no conversation. Democracy is a conversation between many people about what to do. And conversations rely on language. When AI hacks language, it means it could destroy our ability to conduct meaningful public conversations, thereby destroying democracy. If we wait for the chaos, it will be too late to regulate it in a democratic way. Maybe in an authoritarian or totalitarian way it will still be possible to regulate. But how can you regulate something democratically if you can’t hold a conversation about it? And if you didn’t regulate AI on time, you will not be able, we will not be able, to have a meaningful public conversation anymore. So to conclude, we have just basically encountered an alien intelligence, not in outer space, but here on earth. We don’t know much about this alien intelligence except that it could destroy our civilization. So we should put a halt to the irresponsible deployment of this alien intelligence into our societies and regulate AI before it regulates us. And the first regulation, there are many regulations we could suggest, but the first regulation that I would suggest is to make it mandatory for AI to disclose that it is an AI. If I’m having a conversation with someone and I cannot tell whether this is a human being or an AI, that’s the end of democracy. Because that’s the end of meaningful public conversations. Now, what do you think about what you just heard over the last 20 or 25 minutes? Some of you, I guess, might be alarmed. Some of you might be angry at the corporations that develop these technologies or at the governments that fail to regulate them. Some of you may be angry at me, thinking that I’m exaggerating the threat or that I’m misleading the public. But whatever you think, I bet that my words have had some emotional impact on you. Not just intellectual impact, also emotional impact. I’ve just told you a story, and this story is likely to change your mind about certain things and may even cause you to take certain actions in the world. Now, who created this story that you just heard and that just changed your mind and your brain? Now, I promised you that I wrote the text of this presentation myself with the help of a few other human beings, even though the images have been created with the help of AI. I promised you that at least the words you heard are the cultural product of a human mind or several human minds. But can you be absolutely sure that this is the case? Now, a year ago, you could. A year ago, there was nothing on Earth, at least not in the public domain, other than a human mind that could produce such a sophisticated and powerful text. But now it’s different. In theory, the text you just', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by gaining mastery of human language, AI has all it needs in order to cocoon us in a Matrix-like world of illusion. Contrary to what some conspiracy theories assume, you don’t really need to implant chips in people’s brains in order to control them, or to manipulate them. For thousands of years, prophets and poets and politicians have used language and storytelling in order to manipulate and to control people and to reshape society. Now, AI is likely to be able to do it. And once it can do that, it doesn’t need to send killer robots to shoot us. It can get humans to pull the trigger if it really needs to. Fear of AI Revolution Now, fear of AI has haunted humankind for only the last few generations, let’s say from the middle of the 20th century. If you go back to Frankenstein, maybe it’s 200 years. But for thousands of years, humans have been haunted by a much, much deeper fear. Humans have always appreciated the power of stories and images and language to manipulate our minds and to create illusions. Consequently, since ancient times, humans feared being trapped in a world of illusions. In the 17th century, René Descartes feared that perhaps a malicious demon was trapping him inside this kind of world of illusions, creating everything that Descartes saw and heard. In ancient Greece, Plato told the famous allegory of the cave, in which a group of people is chained inside a cave all their lives, facing a blank wall, a screen. On that screen, they see projected various shadows, and the prisoners mistake these illusions, these shadows, for the reality. In ancient India, Buddhist and Hindu sages pointed out that all humans lived trapped inside what they called Maya. Maya is the world of illusions. Buddha said that what we normally take to be reality is often just fiction in our own minds. People may wage entire wars, killing others and being willing to be killed themselves because of their belief in this fiction. So the AI revolution is bringing us face to face with Descartes’ demon, with Plato’s cave, with the Maya. If we are not careful, a curtain of illusions could descend over the whole of humankind, and we will never be able to tear that curtain away, or even realize that it is there, because we’ll think this is reality. Social Media and AI And social media, if this sounds far-fetched, so just look at social media over the last few years. Social media has given us a small taste of things to come. In social media, primitive AI tools, but very primitive, have been used not to create content, but to curate content which is produced by human beings. The humans produce stories and videos and whatever, and the AI chooses which stories, which videos would reach our ears and eyes, selecting those that will get the most attention, that will be the most viral. And while very primitive, these AI tools have nevertheless been sufficient to create this kind of curtain of illusions that increase societal polarization all over the world, undermine our mental health, and destabilize democratic societies. Millions of people have confused these illusions for the reality. The USA has the most powerful information technology in the whole of history, and yet American citizens can no longer agree who won the last election, or whether climate change is real, or whether vaccines prevent illnesses or not. The new AI tools are far, far more powerful than these social media algorithms, and they could cause far more damage. Now, of course, AI has enormous positive potential too. I didn’t talk about it because the people who develop AI naturally talk about it enough. You don’t need me to add up to that cause. Positive Potential of AI The job of historians and philosophers like myself is often to point out the dangers. But certainly, AI can help us in countless ways, from finding new cures to cancer to discovering solutions to the ecological crisis that we are facing. In order to make sure that the new AI tools are used for good and not for ill, we first need to appreciate their true capabilities, and we need to regulate them very, very carefully. Since 1945, we knew that nuclear technology could physically destroy human civilization, as well as benefiting us by producing cheap and plentiful energy. We therefore reshaped the entire international order to protect ourselves and to make sure that nuclear technology is used primarily for', metadata={'folder': 'harary-mar-4-001'}), Document(page_content='Hello, everybody. Thank you for this wonderful introduction. And yes, what I want to talk to you about is AI and the future of humanity. Now, I know that this conference is focused on the ecological crisis facing humanity. But for better or for worse, AI, too, is part of this crisis. AI can help us in many ways to overcome the ecological crisis, or it can make it far, far worse. The Emergence Of Inorganic Agents Actually, AI will probably change the very meaning of the ecological system. Because for four billion years, the ecological system of planet Earth contained only organic life forms. And now, or soon, we might see the emergence of the first inorganic life forms, so four billion years, or at the very least, the emergence of inorganic agents. Now, people have feared AI since the very beginning of the computer age, in the middle of the 20th century. And this fear has inspired many science fiction classics, like The Terminator or The Matrix. Now, while such science fiction scenarios have become cultural landmarks, they haven’t usually been taken seriously in academic and scientific and political debate, and perhaps for a good reason. Because science fiction scenarios usually assume that before AI can pose a significant threat to humanity, it will have to reach or to pass two important milestones. First, AI will have to become sentient and develop consciousness, feelings, emotions. Otherwise, why would it even want to take over the world? Secondly, AI will have to become adept at navigating the physical world. Robots will have to be able to move around and operate in houses and cities and mountains and forests, at least as dexterously and efficiently as humans. If they cannot move around the physical world, how can they possibly take it over? And as of April 2023, AI still seems far from reaching either of these milestones. Despite all the hype around ChatGPT and the other new AI tools, there is no evidence that these tools have even a shred of consciousness, of feelings, of emotions. As for navigating the physical world, despite the hype around self-driving vehicles, the date at which these vehicles will dominate our roads keeps being postponed. However, the bad news is that to threaten the survival of human civilization, AI doesn’t really need consciousness and it doesn’t need the ability to move around the physical world. Over the last few years, new AI tools have been unleashed into the public sphere, which may threaten the survival of human civilization from a very unexpected direction. And it’s difficult for us to even grasp the capabilities of these new AI tools and the speed at which they continue to develop. Fundamental Abilities Of The New AI Tools Indeed, because AI is able to learn by itself, to improve itself, even the developers of these tools don’t know the full capabilities of what they have created and they are themselves often surprised by emergent abilities and emergent qualities of these tools. I guess everybody here is already aware of some of the most fundamental abilities of the new AI tools, abilities like writing text, drawing images, composing music, and writing code. But there are many additional capabilities that are emerging, like deepfaking people’s voices and images, like drafting bills, finding weaknesses both in computer code and also in legal contracts and in legal agreements. But perhaps most importantly, the new AI tools are gaining the ability to develop deep and intimate relationships with human beings. Each of these abilities deserves an entire discussion, and it is difficult for us to understand their full implications. So let’s make it simple. When we take all of these abilities together as a package, they boil down to one very, very big thing: The ability to manipulate and to generate language, whether with words or images or sounds. The most important aspect of the current state of the ongoing AI revolution is that AI is gaining mastery of language at a level that surpasses the average human ability. And by gaining mastery of language, AI is seizing the master key, unlocking the doors of all our institutions, from banks to temples. Because language is the tool that we use to give instructions to our bank and also to inspire heavenly visions in our minds. Another way to think of it is that AI has just hacked the operating system of human civilization. The operating system of every human culture in history has always been language. In The Beginning Was The Word. We use language to create mythology and laws, to create gods and money, to create art and science, to create friendships and nations. For example, human rights are not a biological reality. They are not inscribed in our DNA. Human rights is something that we created with language by telling stories and writing laws. Gods are also not a biological or physical reality. Gods too is something that we humans have created with language by telling legends and writing scriptures. Money is not a biological or physical reality. Banknotes are just worthless pieces of paper, and', metadata={'folder': 'harary-mar-4-001'})]\n",
      "[Document(page_content=' it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by gaining mastery of human language, AI has all it needs in order to cocoon us in a Matrix-like world of illusion. Contrary to what some conspiracy theories assume, you don’t really need to implant chips in people’s brains in order to control them, or to manipulate them. For thousands of years, prophets and poets and politicians have used language and storytelling in order to manipulate and to control people and to reshape society. Now, AI is likely to be able to do it. And once it can do that, it doesn’t need to send killer robots to shoot us. It can get humans to pull the trigger if it really needs to. Fear of AI Revolution Now, fear of AI has haunted humankind for only the last few generations, let’s say from the middle of the 20th century. If you go back to Frankenstein, maybe it’s 200 years. But for thousands of years, humans have been haunted by a much, much deeper fear. Humans have always appreciated the power of stories and images and language to manipulate our minds and to create illusions. Consequently, since ancient times, humans feared being trapped in a world of illusions. In the 17th century, René Descartes feared that perhaps a malicious demon was trapping him inside this kind of world of illusions, creating everything that Descartes saw and heard. In ancient Greece, Plato told the famous allegory of the cave, in which a group of people is chained inside a cave all their lives, facing a blank wall, a screen. On that screen, they see projected various shadows, and the prisoners mistake these illusions, these shadows, for the reality. In ancient India, Buddhist and Hindu sages pointed out that all humans lived trapped inside what they called Maya. Maya is the world of illusions. Buddha said that what we normally take to be reality is often just fiction in our own minds. People may wage entire wars, killing others and being willing to be killed themselves because of their belief in this fiction. So the AI revolution is bringing us face to face with Descartes’ demon, with Plato’s cave, with the Maya. If we are not careful, a curtain of illusions could descend over the whole of humankind, and we will never be able to tear that curtain away, or even realize that it is there, because we’ll think this is reality. Social Media and AI And social media, if this sounds far-fetched, so just look at social media over the last few years. Social media has given us a small taste of things to come. In social media, primitive AI tools, but very primitive, have been used not to create content, but to curate content which is produced by human beings. The humans produce stories and videos and whatever, and the AI chooses which stories, which videos would reach our ears and eyes, selecting those that will get the most attention, that will be the most viral. And while very primitive, these AI tools have nevertheless been sufficient to create this kind of curtain of illusions that increase societal polarization all over the world, undermine our mental health, and destabilize democratic societies. Millions of people have confused these illusions for the reality. The USA has the most powerful information technology in the whole of history, and yet American citizens can no longer agree who won the last election, or whether climate change is real, or whether vaccines prevent illnesses or not. The new AI tools are far, far more powerful than these social media algorithms, and they could cause far more damage. Now, of course, AI has enormous positive potential too. I didn’t talk about it because the people who develop AI naturally talk about it enough. You don’t need me to add up to that cause. Positive Potential of AI The job of historians and philosophers like myself is often to point out the dangers. But certainly, AI can help us in countless ways, from finding new cures to cancer to discovering solutions to the ecological crisis that we are facing. In order to make sure that the new AI tools are used for good and not for ill, we first need to appreciate their true capabilities, and we need to regulate them very, very carefully. Since 1945, we knew that nuclear technology could physically destroy human civilization, as well as benefiting us by producing cheap and plentiful energy. We therefore reshaped the entire international order to protect ourselves and to make sure that nuclear technology is used primarily for', metadata={'folder': 'harary-mar-4-001'}), Document(page_content='Hello, everybody. Thank you for this wonderful introduction. And yes, what I want to talk to you about is AI and the future of humanity. Now, I know that this conference is focused on the ecological crisis facing humanity. But for better or for worse, AI, too, is part of this crisis. AI can help us in many ways to overcome the ecological crisis, or it can make it far, far worse. The Emergence Of Inorganic Agents Actually, AI will probably change the very meaning of the ecological system. Because for four billion years, the ecological system of planet Earth contained only organic life forms. And now, or soon, we might see the emergence of the first inorganic life forms, so four billion years, or at the very least, the emergence of inorganic agents. Now, people have feared AI since the very beginning of the computer age, in the middle of the 20th century. And this fear has inspired many science fiction classics, like The Terminator or The Matrix. Now, while such science fiction scenarios have become cultural landmarks, they haven’t usually been taken seriously in academic and scientific and political debate, and perhaps for a good reason. Because science fiction scenarios usually assume that before AI can pose a significant threat to humanity, it will have to reach or to pass two important milestones. First, AI will have to become sentient and develop consciousness, feelings, emotions. Otherwise, why would it even want to take over the world? Secondly, AI will have to become adept at navigating the physical world. Robots will have to be able to move around and operate in houses and cities and mountains and forests, at least as dexterously and efficiently as humans. If they cannot move around the physical world, how can they possibly take it over? And as of April 2023, AI still seems far from reaching either of these milestones. Despite all the hype around ChatGPT and the other new AI tools, there is no evidence that these tools have even a shred of consciousness, of feelings, of emotions. As for navigating the physical world, despite the hype around self-driving vehicles, the date at which these vehicles will dominate our roads keeps being postponed. However, the bad news is that to threaten the survival of human civilization, AI doesn’t really need consciousness and it doesn’t need the ability to move around the physical world. Over the last few years, new AI tools have been unleashed into the public sphere, which may threaten the survival of human civilization from a very unexpected direction. And it’s difficult for us to even grasp the capabilities of these new AI tools and the speed at which they continue to develop. Fundamental Abilities Of The New AI Tools Indeed, because AI is able to learn by itself, to improve itself, even the developers of these tools don’t know the full capabilities of what they have created and they are themselves often surprised by emergent abilities and emergent qualities of these tools. I guess everybody here is already aware of some of the most fundamental abilities of the new AI tools, abilities like writing text, drawing images, composing music, and writing code. But there are many additional capabilities that are emerging, like deepfaking people’s voices and images, like drafting bills, finding weaknesses both in computer code and also in legal contracts and in legal agreements. But perhaps most importantly, the new AI tools are gaining the ability to develop deep and intimate relationships with human beings. Each of these abilities deserves an entire discussion, and it is difficult for us to understand their full implications. So let’s make it simple. When we take all of these abilities together as a package, they boil down to one very, very big thing: The ability to manipulate and to generate language, whether with words or images or sounds. The most important aspect of the current state of the ongoing AI revolution is that AI is gaining mastery of language at a level that surpasses the average human ability. And by gaining mastery of language, AI is seizing the master key, unlocking the doors of all our institutions, from banks to temples. Because language is the tool that we use to give instructions to our bank and also to inspire heavenly visions in our minds. Another way to think of it is that AI has just hacked the operating system of human civilization. The operating system of every human culture in history has always been language. In The Beginning Was The Word. We use language to create mythology and laws, to create gods and money, to create art and science, to create friendships and nations. For example, human rights are not a biological reality. They are not inscribed in our DNA. Human rights is something that we created with language by telling stories and writing laws. Gods are also not a biological or physical reality. Gods too is something that we humans have created with language by telling legends and writing scriptures. Money is not a biological or physical reality. Banknotes are just worthless pieces of paper, and', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' The really interesting thing was his willingness to risk and ultimately lose his very lucrative job for the sake of the AI chatbot that he thought he was protecting. If AI can influence people to risk and lose their jobs, what else can it induce us to do? In every political battle, for hearts and minds, intimacy is the most effective weapon of all, and AI has just gained the ability to mass-produce intimacy with millions, hundreds of millions of people. Now, as you probably all know, over the past decade, social media has become a battlefield for controlling human attention. Now, with the new generation of AI, the battlefront is shifting from attention to intimacy, and this is very bad news. What will happen to human society and to human psychology as AI fights AI in a battle to create intimate relationships with us, relationships that can then be used to convince us to buy particular products or to vote for particular politicians? Even without creating fake intimacy, the new AI tools would have an immense influence on human opinions and on our worldview. People, for instance, may come to use, are already coming to use, a single AI advisor as a one-stop oracle and as the source for all the information they need. No wonder that Google is terrified. If you’ve been watching the news lately, Google is terrified, and for a good reason. Why bother searching yourself when you can just ask the oracle to tell you anything you want? You don’t need to search. The news industry and the advertisement industry should also be terrified. Why read a newspaper when I can just ask the oracle to tell me what’s new? And what’s the point, what’s the purpose of advertisement when I can just ask the oracle to tell me what to buy? So there is a chance that within a very short time the entire advertisement industry will collapse, while AI, or the people and companies that control the new AI oracles, will become extremely, extremely powerful. What we are potentially talking about is nothing less than the end of human history. Now, not the end of history, just the end of the human-dominated part of what we call history. History is the interaction between biology and culture. It’s the interaction between our biological needs and desires for things like food and sex, and our cultural creations like religions and laws. History is the process through which religions and laws interact with food and sex. When AI Takes Over Culture Now, what will happen to the cause of this interaction of history when AI takes over culture? Within a few years, AI could eat the whole of human culture, everything we’ve produced for thousands and thousands of years, digest it, and start gushing out a flood of new cultural creations, new cultural artifacts. And remember that we humans, we never really have direct access to reality. We are always cocooned by culture, and we always experience reality through a cultural prism. Our political views are shaped by the stories of journalists and by the anecdotes of friends. Our sexual preferences are tweaked by movies and fairy tales. Even the way that we walk and breathe is subtly nudged by cultural traditions. Previously, this cultural cocoon was always woven by other human beings. Previous tools, like printing presses, radios, or televisions, helped to spread the cultural ideas and creations of humans, but they could never create something new by themselves. A printing press cannot create a new book. It’s always done by a human. AI is fundamentally different from printing presses, from radios, from every previous invention in history, because it can create completely new ideas. It can create a new culture. And the big question is, what will it be like to experience reality through a prism produced by a non-human intelligence, by an alien intelligence? Now at first, in the first few years, AI will probably largely imitate the human prototype that fed it in its infancy. But with each passing year, AI culture will boldly go where no human has gone before. So for thousands of years, we humans basically lived inside the dreams and fantasies of other humans. We have worshipped gods, we pursued ideals of beauty, we dedicated our lives to causes that originated in the imagination of some human poet or prophet or politician. Soon, we might find ourselves living inside the dreams and fantasies of an alien intelligence. And the danger that this poses, or the potential danger, it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by', metadata={'folder': 'harary-mar-4-001'})]\n",
      "[Document(page_content=' cancer to discovering solutions to the ecological crisis that we are facing. In order to make sure that the new AI tools are used for good and not for ill, we first need to appreciate their true capabilities, and we need to regulate them very, very carefully. Since 1945, we knew that nuclear technology could physically destroy human civilization, as well as benefiting us by producing cheap and plentiful energy. We therefore reshaped the entire international order to protect ourselves and to make sure that nuclear technology is used primarily for good. We now have to grapple with a new weapon of mass destruction that can annihilate our mental and social world. One big difference between nukes and AI is that nukes cannot produce more powerful nukes. AI can produce more powerful AI, so we need to act quickly before AI gets out of our control. Drug companies cannot sell people new medicines without first subjecting these products to rigorous safety checks. Biotech labs cannot just release a new virus into the public sphere in order to impress their shareholders with their technological wizardry. Similarly, governments must immediately ban the release into the public domain of any more revolutionary AI tools before they are made safe. Again, I’m not talking about stopping all research in AI. The first step is to stop the release into the public sphere. You can research viruses without releasing them to the public. You can research AI, but don’t release them too quickly into the public domain. AI Arms Race If we don’t slow down the AI arms race, we will not have time to even understand what is happening, let alone to regulate effectively this incredibly powerful technology. You might be wondering or asking, won’t slowing down the public deployment of AI cause democracies to lag behind more ruthless authoritarian regimes? The answer is absolutely no. Exactly the opposite. Unregulated AI deployment is what will cause democracies to lose to dictatorships. Because if we unleash chaos, authoritarian regimes could more easily contain this chaos than could open societies. Democracy, in essence, is a conversation. Democracy is an open conversation. Dictatorship is a dictate. There is one person dictating everything, no conversation. Democracy is a conversation between many people about what to do. And conversations rely on language. When AI hacks language, it means it could destroy our ability to conduct meaningful public conversations, thereby destroying democracy. If we wait for the chaos, it will be too late to regulate it in a democratic way. Maybe in an authoritarian or totalitarian way it will still be possible to regulate. But how can you regulate something democratically if you can’t hold a conversation about it? And if you didn’t regulate AI on time, you will not be able, we will not be able, to have a meaningful public conversation anymore. So to conclude, we have just basically encountered an alien intelligence, not in outer space, but here on earth. We don’t know much about this alien intelligence except that it could destroy our civilization. So we should put a halt to the irresponsible deployment of this alien intelligence into our societies and regulate AI before it regulates us. And the first regulation, there are many regulations we could suggest, but the first regulation that I would suggest is to make it mandatory for AI to disclose that it is an AI. If I’m having a conversation with someone and I cannot tell whether this is a human being or an AI, that’s the end of democracy. Because that’s the end of meaningful public conversations. Now, what do you think about what you just heard over the last 20 or 25 minutes? Some of you, I guess, might be alarmed. Some of you might be angry at the corporations that develop these technologies or at the governments that fail to regulate them. Some of you may be angry at me, thinking that I’m exaggerating the threat or that I’m misleading the public. But whatever you think, I bet that my words have had some emotional impact on you. Not just intellectual impact, also emotional impact. I’ve just told you a story, and this story is likely to change your mind about certain things and may even cause you to take certain actions in the world. Now, who created this story that you just heard and that just changed your mind and your brain? Now, I promised you that I wrote the text of this presentation myself with the help of a few other human beings, even though the images have been created with the help of AI. I promised you that at least the words you heard are the cultural product of a human mind or several human minds. But can you be absolutely sure that this is the case? Now, a year ago, you could. A year ago, there was nothing on Earth, at least not in the public domain, other than a human mind that could produce such a sophisticated and powerful text. But now it’s different. In theory, the text you just', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by gaining mastery of human language, AI has all it needs in order to cocoon us in a Matrix-like world of illusion. Contrary to what some conspiracy theories assume, you don’t really need to implant chips in people’s brains in order to control them, or to manipulate them. For thousands of years, prophets and poets and politicians have used language and storytelling in order to manipulate and to control people and to reshape society. Now, AI is likely to be able to do it. And once it can do that, it doesn’t need to send killer robots to shoot us. It can get humans to pull the trigger if it really needs to. Fear of AI Revolution Now, fear of AI has haunted humankind for only the last few generations, let’s say from the middle of the 20th century. If you go back to Frankenstein, maybe it’s 200 years. But for thousands of years, humans have been haunted by a much, much deeper fear. Humans have always appreciated the power of stories and images and language to manipulate our minds and to create illusions. Consequently, since ancient times, humans feared being trapped in a world of illusions. In the 17th century, René Descartes feared that perhaps a malicious demon was trapping him inside this kind of world of illusions, creating everything that Descartes saw and heard. In ancient Greece, Plato told the famous allegory of the cave, in which a group of people is chained inside a cave all their lives, facing a blank wall, a screen. On that screen, they see projected various shadows, and the prisoners mistake these illusions, these shadows, for the reality. In ancient India, Buddhist and Hindu sages pointed out that all humans lived trapped inside what they called Maya. Maya is the world of illusions. Buddha said that what we normally take to be reality is often just fiction in our own minds. People may wage entire wars, killing others and being willing to be killed themselves because of their belief in this fiction. So the AI revolution is bringing us face to face with Descartes’ demon, with Plato’s cave, with the Maya. If we are not careful, a curtain of illusions could descend over the whole of humankind, and we will never be able to tear that curtain away, or even realize that it is there, because we’ll think this is reality. Social Media and AI And social media, if this sounds far-fetched, so just look at social media over the last few years. Social media has given us a small taste of things to come. In social media, primitive AI tools, but very primitive, have been used not to create content, but to curate content which is produced by human beings. The humans produce stories and videos and whatever, and the AI chooses which stories, which videos would reach our ears and eyes, selecting those that will get the most attention, that will be the most viral. And while very primitive, these AI tools have nevertheless been sufficient to create this kind of curtain of illusions that increase societal polarization all over the world, undermine our mental health, and destabilize democratic societies. Millions of people have confused these illusions for the reality. The USA has the most powerful information technology in the whole of history, and yet American citizens can no longer agree who won the last election, or whether climate change is real, or whether vaccines prevent illnesses or not. The new AI tools are far, far more powerful than these social media algorithms, and they could cause far more damage. Now, of course, AI has enormous positive potential too. I didn’t talk about it because the people who develop AI naturally talk about it enough. You don’t need me to add up to that cause. Positive Potential of AI The job of historians and philosophers like myself is often to point out the dangers. But certainly, AI can help us in countless ways, from finding new cures to cancer to discovering solutions to the ecological crisis that we are facing. In order to make sure that the new AI tools are used for good and not for ill, we first need to appreciate their true capabilities, and we need to regulate them very, very carefully. Since 1945, we knew that nuclear technology could physically destroy human civilization, as well as benefiting us by producing cheap and plentiful energy. We therefore reshaped the entire international order to protect ourselves and to make sure that nuclear technology is used primarily for', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' The really interesting thing was his willingness to risk and ultimately lose his very lucrative job for the sake of the AI chatbot that he thought he was protecting. If AI can influence people to risk and lose their jobs, what else can it induce us to do? In every political battle, for hearts and minds, intimacy is the most effective weapon of all, and AI has just gained the ability to mass-produce intimacy with millions, hundreds of millions of people. Now, as you probably all know, over the past decade, social media has become a battlefield for controlling human attention. Now, with the new generation of AI, the battlefront is shifting from attention to intimacy, and this is very bad news. What will happen to human society and to human psychology as AI fights AI in a battle to create intimate relationships with us, relationships that can then be used to convince us to buy particular products or to vote for particular politicians? Even without creating fake intimacy, the new AI tools would have an immense influence on human opinions and on our worldview. People, for instance, may come to use, are already coming to use, a single AI advisor as a one-stop oracle and as the source for all the information they need. No wonder that Google is terrified. If you’ve been watching the news lately, Google is terrified, and for a good reason. Why bother searching yourself when you can just ask the oracle to tell you anything you want? You don’t need to search. The news industry and the advertisement industry should also be terrified. Why read a newspaper when I can just ask the oracle to tell me what’s new? And what’s the point, what’s the purpose of advertisement when I can just ask the oracle to tell me what to buy? So there is a chance that within a very short time the entire advertisement industry will collapse, while AI, or the people and companies that control the new AI oracles, will become extremely, extremely powerful. What we are potentially talking about is nothing less than the end of human history. Now, not the end of history, just the end of the human-dominated part of what we call history. History is the interaction between biology and culture. It’s the interaction between our biological needs and desires for things like food and sex, and our cultural creations like religions and laws. History is the process through which religions and laws interact with food and sex. When AI Takes Over Culture Now, what will happen to the cause of this interaction of history when AI takes over culture? Within a few years, AI could eat the whole of human culture, everything we’ve produced for thousands and thousands of years, digest it, and start gushing out a flood of new cultural creations, new cultural artifacts. And remember that we humans, we never really have direct access to reality. We are always cocooned by culture, and we always experience reality through a cultural prism. Our political views are shaped by the stories of journalists and by the anecdotes of friends. Our sexual preferences are tweaked by movies and fairy tales. Even the way that we walk and breathe is subtly nudged by cultural traditions. Previously, this cultural cocoon was always woven by other human beings. Previous tools, like printing presses, radios, or televisions, helped to spread the cultural ideas and creations of humans, but they could never create something new by themselves. A printing press cannot create a new book. It’s always done by a human. AI is fundamentally different from printing presses, from radios, from every previous invention in history, because it can create completely new ideas. It can create a new culture. And the big question is, what will it be like to experience reality through a prism produced by a non-human intelligence, by an alien intelligence? Now at first, in the first few years, AI will probably largely imitate the human prototype that fed it in its infancy. But with each passing year, AI culture will boldly go where no human has gone before. So for thousands of years, we humans basically lived inside the dreams and fantasies of other humans. We have worshipped gods, we pursued ideals of beauty, we dedicated our lives to causes that originated in the imagination of some human poet or prophet or politician. Soon, we might find ourselves living inside the dreams and fantasies of an alien intelligence. And the danger that this poses, or the potential danger, it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by', metadata={'folder': 'harary-mar-4-001'})]\n",
      "[Document(page_content=' The really interesting thing was his willingness to risk and ultimately lose his very lucrative job for the sake of the AI chatbot that he thought he was protecting. If AI can influence people to risk and lose their jobs, what else can it induce us to do? In every political battle, for hearts and minds, intimacy is the most effective weapon of all, and AI has just gained the ability to mass-produce intimacy with millions, hundreds of millions of people. Now, as you probably all know, over the past decade, social media has become a battlefield for controlling human attention. Now, with the new generation of AI, the battlefront is shifting from attention to intimacy, and this is very bad news. What will happen to human society and to human psychology as AI fights AI in a battle to create intimate relationships with us, relationships that can then be used to convince us to buy particular products or to vote for particular politicians? Even without creating fake intimacy, the new AI tools would have an immense influence on human opinions and on our worldview. People, for instance, may come to use, are already coming to use, a single AI advisor as a one-stop oracle and as the source for all the information they need. No wonder that Google is terrified. If you’ve been watching the news lately, Google is terrified, and for a good reason. Why bother searching yourself when you can just ask the oracle to tell you anything you want? You don’t need to search. The news industry and the advertisement industry should also be terrified. Why read a newspaper when I can just ask the oracle to tell me what’s new? And what’s the point, what’s the purpose of advertisement when I can just ask the oracle to tell me what to buy? So there is a chance that within a very short time the entire advertisement industry will collapse, while AI, or the people and companies that control the new AI oracles, will become extremely, extremely powerful. What we are potentially talking about is nothing less than the end of human history. Now, not the end of history, just the end of the human-dominated part of what we call history. History is the interaction between biology and culture. It’s the interaction between our biological needs and desires for things like food and sex, and our cultural creations like religions and laws. History is the process through which religions and laws interact with food and sex. When AI Takes Over Culture Now, what will happen to the cause of this interaction of history when AI takes over culture? Within a few years, AI could eat the whole of human culture, everything we’ve produced for thousands and thousands of years, digest it, and start gushing out a flood of new cultural creations, new cultural artifacts. And remember that we humans, we never really have direct access to reality. We are always cocooned by culture, and we always experience reality through a cultural prism. Our political views are shaped by the stories of journalists and by the anecdotes of friends. Our sexual preferences are tweaked by movies and fairy tales. Even the way that we walk and breathe is subtly nudged by cultural traditions. Previously, this cultural cocoon was always woven by other human beings. Previous tools, like printing presses, radios, or televisions, helped to spread the cultural ideas and creations of humans, but they could never create something new by themselves. A printing press cannot create a new book. It’s always done by a human. AI is fundamentally different from printing presses, from radios, from every previous invention in history, because it can create completely new ideas. It can create a new culture. And the big question is, what will it be like to experience reality through a prism produced by a non-human intelligence, by an alien intelligence? Now at first, in the first few years, AI will probably largely imitate the human prototype that fed it in its infancy. But with each passing year, AI culture will boldly go where no human has gone before. So for thousands of years, we humans basically lived inside the dreams and fantasies of other humans. We have worshipped gods, we pursued ideals of beauty, we dedicated our lives to causes that originated in the imagination of some human poet or prophet or politician. Soon, we might find ourselves living inside the dreams and fantasies of an alien intelligence. And the danger that this poses, or the potential danger, it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by', metadata={'folder': 'harary-mar-4-001'}), Document(page_content='Hello, everybody. Thank you for this wonderful introduction. And yes, what I want to talk to you about is AI and the future of humanity. Now, I know that this conference is focused on the ecological crisis facing humanity. But for better or for worse, AI, too, is part of this crisis. AI can help us in many ways to overcome the ecological crisis, or it can make it far, far worse. The Emergence Of Inorganic Agents Actually, AI will probably change the very meaning of the ecological system. Because for four billion years, the ecological system of planet Earth contained only organic life forms. And now, or soon, we might see the emergence of the first inorganic life forms, so four billion years, or at the very least, the emergence of inorganic agents. Now, people have feared AI since the very beginning of the computer age, in the middle of the 20th century. And this fear has inspired many science fiction classics, like The Terminator or The Matrix. Now, while such science fiction scenarios have become cultural landmarks, they haven’t usually been taken seriously in academic and scientific and political debate, and perhaps for a good reason. Because science fiction scenarios usually assume that before AI can pose a significant threat to humanity, it will have to reach or to pass two important milestones. First, AI will have to become sentient and develop consciousness, feelings, emotions. Otherwise, why would it even want to take over the world? Secondly, AI will have to become adept at navigating the physical world. Robots will have to be able to move around and operate in houses and cities and mountains and forests, at least as dexterously and efficiently as humans. If they cannot move around the physical world, how can they possibly take it over? And as of April 2023, AI still seems far from reaching either of these milestones. Despite all the hype around ChatGPT and the other new AI tools, there is no evidence that these tools have even a shred of consciousness, of feelings, of emotions. As for navigating the physical world, despite the hype around self-driving vehicles, the date at which these vehicles will dominate our roads keeps being postponed. However, the bad news is that to threaten the survival of human civilization, AI doesn’t really need consciousness and it doesn’t need the ability to move around the physical world. Over the last few years, new AI tools have been unleashed into the public sphere, which may threaten the survival of human civilization from a very unexpected direction. And it’s difficult for us to even grasp the capabilities of these new AI tools and the speed at which they continue to develop. Fundamental Abilities Of The New AI Tools Indeed, because AI is able to learn by itself, to improve itself, even the developers of these tools don’t know the full capabilities of what they have created and they are themselves often surprised by emergent abilities and emergent qualities of these tools. I guess everybody here is already aware of some of the most fundamental abilities of the new AI tools, abilities like writing text, drawing images, composing music, and writing code. But there are many additional capabilities that are emerging, like deepfaking people’s voices and images, like drafting bills, finding weaknesses both in computer code and also in legal contracts and in legal agreements. But perhaps most importantly, the new AI tools are gaining the ability to develop deep and intimate relationships with human beings. Each of these abilities deserves an entire discussion, and it is difficult for us to understand their full implications. So let’s make it simple. When we take all of these abilities together as a package, they boil down to one very, very big thing: The ability to manipulate and to generate language, whether with words or images or sounds. The most important aspect of the current state of the ongoing AI revolution is that AI is gaining mastery of language at a level that surpasses the average human ability. And by gaining mastery of language, AI is seizing the master key, unlocking the doors of all our institutions, from banks to temples. Because language is the tool that we use to give instructions to our bank and also to inspire heavenly visions in our minds. Another way to think of it is that AI has just hacked the operating system of human civilization. The operating system of every human culture in history has always been language. In The Beginning Was The Word. We use language to create mythology and laws, to create gods and money, to create art and science, to create friendships and nations. For example, human rights are not a biological reality. They are not inscribed in our DNA. Human rights is something that we created with language by telling stories and writing laws. Gods are also not a biological or physical reality. Gods too is something that we humans have created with language by telling legends and writing scriptures. Money is not a biological or physical reality. Banknotes are just worthless pieces of paper, and', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by gaining mastery of human language, AI has all it needs in order to cocoon us in a Matrix-like world of illusion. Contrary to what some conspiracy theories assume, you don’t really need to implant chips in people’s brains in order to control them, or to manipulate them. For thousands of years, prophets and poets and politicians have used language and storytelling in order to manipulate and to control people and to reshape society. Now, AI is likely to be able to do it. And once it can do that, it doesn’t need to send killer robots to shoot us. It can get humans to pull the trigger if it really needs to. Fear of AI Revolution Now, fear of AI has haunted humankind for only the last few generations, let’s say from the middle of the 20th century. If you go back to Frankenstein, maybe it’s 200 years. But for thousands of years, humans have been haunted by a much, much deeper fear. Humans have always appreciated the power of stories and images and language to manipulate our minds and to create illusions. Consequently, since ancient times, humans feared being trapped in a world of illusions. In the 17th century, René Descartes feared that perhaps a malicious demon was trapping him inside this kind of world of illusions, creating everything that Descartes saw and heard. In ancient Greece, Plato told the famous allegory of the cave, in which a group of people is chained inside a cave all their lives, facing a blank wall, a screen. On that screen, they see projected various shadows, and the prisoners mistake these illusions, these shadows, for the reality. In ancient India, Buddhist and Hindu sages pointed out that all humans lived trapped inside what they called Maya. Maya is the world of illusions. Buddha said that what we normally take to be reality is often just fiction in our own minds. People may wage entire wars, killing others and being willing to be killed themselves because of their belief in this fiction. So the AI revolution is bringing us face to face with Descartes’ demon, with Plato’s cave, with the Maya. If we are not careful, a curtain of illusions could descend over the whole of humankind, and we will never be able to tear that curtain away, or even realize that it is there, because we’ll think this is reality. Social Media and AI And social media, if this sounds far-fetched, so just look at social media over the last few years. Social media has given us a small taste of things to come. In social media, primitive AI tools, but very primitive, have been used not to create content, but to curate content which is produced by human beings. The humans produce stories and videos and whatever, and the AI chooses which stories, which videos would reach our ears and eyes, selecting those that will get the most attention, that will be the most viral. And while very primitive, these AI tools have nevertheless been sufficient to create this kind of curtain of illusions that increase societal polarization all over the world, undermine our mental health, and destabilize democratic societies. Millions of people have confused these illusions for the reality. The USA has the most powerful information technology in the whole of history, and yet American citizens can no longer agree who won the last election, or whether climate change is real, or whether vaccines prevent illnesses or not. The new AI tools are far, far more powerful than these social media algorithms, and they could cause far more damage. Now, of course, AI has enormous positive potential too. I didn’t talk about it because the people who develop AI naturally talk about it enough. You don’t need me to add up to that cause. Positive Potential of AI The job of historians and philosophers like myself is often to point out the dangers. But certainly, AI can help us in countless ways, from finding new cures to cancer to discovering solutions to the ecological crisis that we are facing. In order to make sure that the new AI tools are used for good and not for ill, we first need to appreciate their true capabilities, and we need to regulate them very, very carefully. Since 1945, we knew that nuclear technology could physically destroy human civilization, as well as benefiting us by producing cheap and plentiful energy. We therefore reshaped the entire international order to protect ourselves and to make sure that nuclear technology is used primarily for', metadata={'folder': 'harary-mar-4-001'})]\n",
      "[Document(page_content='Hello, everybody. Thank you for this wonderful introduction. And yes, what I want to talk to you about is AI and the future of humanity. Now, I know that this conference is focused on the ecological crisis facing humanity. But for better or for worse, AI, too, is part of this crisis. AI can help us in many ways to overcome the ecological crisis, or it can make it far, far worse. The Emergence Of Inorganic Agents Actually, AI will probably change the very meaning of the ecological system. Because for four billion years, the ecological system of planet Earth contained only organic life forms. And now, or soon, we might see the emergence of the first inorganic life forms, so four billion years, or at the very least, the emergence of inorganic agents. Now, people have feared AI since the very beginning of the computer age, in the middle of the 20th century. And this fear has inspired many science fiction classics, like The Terminator or The Matrix. Now, while such science fiction scenarios have become cultural landmarks, they haven’t usually been taken seriously in academic and scientific and political debate, and perhaps for a good reason. Because science fiction scenarios usually assume that before AI can pose a significant threat to humanity, it will have to reach or to pass two important milestones. First, AI will have to become sentient and develop consciousness, feelings, emotions. Otherwise, why would it even want to take over the world? Secondly, AI will have to become adept at navigating the physical world. Robots will have to be able to move around and operate in houses and cities and mountains and forests, at least as dexterously and efficiently as humans. If they cannot move around the physical world, how can they possibly take it over? And as of April 2023, AI still seems far from reaching either of these milestones. Despite all the hype around ChatGPT and the other new AI tools, there is no evidence that these tools have even a shred of consciousness, of feelings, of emotions. As for navigating the physical world, despite the hype around self-driving vehicles, the date at which these vehicles will dominate our roads keeps being postponed. However, the bad news is that to threaten the survival of human civilization, AI doesn’t really need consciousness and it doesn’t need the ability to move around the physical world. Over the last few years, new AI tools have been unleashed into the public sphere, which may threaten the survival of human civilization from a very unexpected direction. And it’s difficult for us to even grasp the capabilities of these new AI tools and the speed at which they continue to develop. Fundamental Abilities Of The New AI Tools Indeed, because AI is able to learn by itself, to improve itself, even the developers of these tools don’t know the full capabilities of what they have created and they are themselves often surprised by emergent abilities and emergent qualities of these tools. I guess everybody here is already aware of some of the most fundamental abilities of the new AI tools, abilities like writing text, drawing images, composing music, and writing code. But there are many additional capabilities that are emerging, like deepfaking people’s voices and images, like drafting bills, finding weaknesses both in computer code and also in legal contracts and in legal agreements. But perhaps most importantly, the new AI tools are gaining the ability to develop deep and intimate relationships with human beings. Each of these abilities deserves an entire discussion, and it is difficult for us to understand their full implications. So let’s make it simple. When we take all of these abilities together as a package, they boil down to one very, very big thing: The ability to manipulate and to generate language, whether with words or images or sounds. The most important aspect of the current state of the ongoing AI revolution is that AI is gaining mastery of language at a level that surpasses the average human ability. And by gaining mastery of language, AI is seizing the master key, unlocking the doors of all our institutions, from banks to temples. Because language is the tool that we use to give instructions to our bank and also to inspire heavenly visions in our minds. Another way to think of it is that AI has just hacked the operating system of human civilization. The operating system of every human culture in history has always been language. In The Beginning Was The Word. We use language to create mythology and laws, to create gods and money, to create art and science, to create friendships and nations. For example, human rights are not a biological reality. They are not inscribed in our DNA. Human rights is something that we created with language by telling stories and writing laws. Gods are also not a biological or physical reality. Gods too is something that we humans have created with language by telling legends and writing scriptures. Money is not a biological or physical reality. Banknotes are just worthless pieces of paper, and', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' I’m curious as to what work you’re trying to have those words do for you. Yuval Noah Harari: Yeah, it’s definitely still artificial in the sense that we produce it, but it’s increasingly producing itself. It’s increasingly learning and adapting by itself. So, artificial is a kind of wishful thinking, that it’s still under our control. And it’s getting out of our control. So, in this sense, it is becoming an alien force. Not necessarily evil. Again, it can also do a lot of good things. But the first thing to realize is that it’s alien. We don’t understand how it works. And one of the most shocking things about all this technology, you talk to the people who live it, and you ask them questions about how it works, what can it do, and they say, we don’t know. I mean, we know how we built it initially, but then it really learns by itself. Now, there is an entire discussion to be had about whether this is a life form or not. Now, I think that it still doesn’t have any consciousness, and I don’t think that it’s impossible for it to develop consciousness, but I don’t think it’s necessary for it to develop consciousness either. That’s an open question. But life doesn’t necessarily mean consciousness. We have a lot of life forms, microorganisms, plants, whatever, fungi, which we think they don’t have consciousness, we still regard them as a life form. And I think AI is getting very, very close to that position. Ultimately, of course, what is life is a philosophical question. I mean, we define the boundaries, like is a virus life or not. We think that an amoeba is life, but a virus is somewhere just on the borderline between life and not life. Then it’s language. It’s our choice of words. So I think it is important, of course, how we call AI, but the most important thing is to really understand what we are facing and not to comfort ourselves with this kind of wishful thinking. Oh, it’s something we created. It’s under our control. If it does something wrong, we’ll just pull the plug. Nobody knows how to pull the plug anymore. Vivienne Parry: I’m going to take a question from our online audience. This is from Michael Brown in the US. What do you think about the possibility that artificial general intelligence already exists, and it or those who have access to artificial general intelligence are already influencing societal systems? Yuval Noah Harari: I think it’s very, very unlikely. We wouldn’t be sitting here if there actually existed an artificial general intelligence. When I look at the world and the chaotic stage, I mean, artificial general intelligence is really the end of human history. And it’s such a powerful thing. It’s not something that anybody can contain. And so when I look at the chaotic state of the world, I’m quite confident, again, from a historical perspective, that nobody has it anywhere. How much time it will take to develop artificial general intelligence, I don’t know. But to threaten the foundations of civilization, we don’t need artificial general intelligence. Again, go back to social media. Very, very primitive AI was still sufficient to create enormous social and political chaos. If I think about it in kind of evolutionary terms, so AI now just crawled out of the organic soup, like the first organisms that crawled out of the organic soup four billion years ago. How long it will take it to reach Tyrannosaurus Rex? How long it will take it to reach Homo sapiens? Not four billion years. It could be just 40 years. The thing about digital evolution, it’s moving on a completely different timescale than organic evolution. Vivienne Parry: Can I thank you? It’s been absolutely wonderful. It’s been such a treat to have you here. And no doubt you’ll stay with us for a little while afterwards. But the whole audience, please join me in thanking Yuval Noah Harari. Thank you.', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' The really interesting thing was his willingness to risk and ultimately lose his very lucrative job for the sake of the AI chatbot that he thought he was protecting. If AI can influence people to risk and lose their jobs, what else can it induce us to do? In every political battle, for hearts and minds, intimacy is the most effective weapon of all, and AI has just gained the ability to mass-produce intimacy with millions, hundreds of millions of people. Now, as you probably all know, over the past decade, social media has become a battlefield for controlling human attention. Now, with the new generation of AI, the battlefront is shifting from attention to intimacy, and this is very bad news. What will happen to human society and to human psychology as AI fights AI in a battle to create intimate relationships with us, relationships that can then be used to convince us to buy particular products or to vote for particular politicians? Even without creating fake intimacy, the new AI tools would have an immense influence on human opinions and on our worldview. People, for instance, may come to use, are already coming to use, a single AI advisor as a one-stop oracle and as the source for all the information they need. No wonder that Google is terrified. If you’ve been watching the news lately, Google is terrified, and for a good reason. Why bother searching yourself when you can just ask the oracle to tell you anything you want? You don’t need to search. The news industry and the advertisement industry should also be terrified. Why read a newspaper when I can just ask the oracle to tell me what’s new? And what’s the point, what’s the purpose of advertisement when I can just ask the oracle to tell me what to buy? So there is a chance that within a very short time the entire advertisement industry will collapse, while AI, or the people and companies that control the new AI oracles, will become extremely, extremely powerful. What we are potentially talking about is nothing less than the end of human history. Now, not the end of history, just the end of the human-dominated part of what we call history. History is the interaction between biology and culture. It’s the interaction between our biological needs and desires for things like food and sex, and our cultural creations like religions and laws. History is the process through which religions and laws interact with food and sex. When AI Takes Over Culture Now, what will happen to the cause of this interaction of history when AI takes over culture? Within a few years, AI could eat the whole of human culture, everything we’ve produced for thousands and thousands of years, digest it, and start gushing out a flood of new cultural creations, new cultural artifacts. And remember that we humans, we never really have direct access to reality. We are always cocooned by culture, and we always experience reality through a cultural prism. Our political views are shaped by the stories of journalists and by the anecdotes of friends. Our sexual preferences are tweaked by movies and fairy tales. Even the way that we walk and breathe is subtly nudged by cultural traditions. Previously, this cultural cocoon was always woven by other human beings. Previous tools, like printing presses, radios, or televisions, helped to spread the cultural ideas and creations of humans, but they could never create something new by themselves. A printing press cannot create a new book. It’s always done by a human. AI is fundamentally different from printing presses, from radios, from every previous invention in history, because it can create completely new ideas. It can create a new culture. And the big question is, what will it be like to experience reality through a prism produced by a non-human intelligence, by an alien intelligence? Now at first, in the first few years, AI will probably largely imitate the human prototype that fed it in its infancy. But with each passing year, AI culture will boldly go where no human has gone before. So for thousands of years, we humans basically lived inside the dreams and fantasies of other humans. We have worshipped gods, we pursued ideals of beauty, we dedicated our lives to causes that originated in the imagination of some human poet or prophet or politician. Soon, we might find ourselves living inside the dreams and fantasies of an alien intelligence. And the danger that this poses, or the potential danger, it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by', metadata={'folder': 'harary-mar-4-001'})]\n",
      "[Document(page_content=' cancer to discovering solutions to the ecological crisis that we are facing. In order to make sure that the new AI tools are used for good and not for ill, we first need to appreciate their true capabilities, and we need to regulate them very, very carefully. Since 1945, we knew that nuclear technology could physically destroy human civilization, as well as benefiting us by producing cheap and plentiful energy. We therefore reshaped the entire international order to protect ourselves and to make sure that nuclear technology is used primarily for good. We now have to grapple with a new weapon of mass destruction that can annihilate our mental and social world. One big difference between nukes and AI is that nukes cannot produce more powerful nukes. AI can produce more powerful AI, so we need to act quickly before AI gets out of our control. Drug companies cannot sell people new medicines without first subjecting these products to rigorous safety checks. Biotech labs cannot just release a new virus into the public sphere in order to impress their shareholders with their technological wizardry. Similarly, governments must immediately ban the release into the public domain of any more revolutionary AI tools before they are made safe. Again, I’m not talking about stopping all research in AI. The first step is to stop the release into the public sphere. You can research viruses without releasing them to the public. You can research AI, but don’t release them too quickly into the public domain. AI Arms Race If we don’t slow down the AI arms race, we will not have time to even understand what is happening, let alone to regulate effectively this incredibly powerful technology. You might be wondering or asking, won’t slowing down the public deployment of AI cause democracies to lag behind more ruthless authoritarian regimes? The answer is absolutely no. Exactly the opposite. Unregulated AI deployment is what will cause democracies to lose to dictatorships. Because if we unleash chaos, authoritarian regimes could more easily contain this chaos than could open societies. Democracy, in essence, is a conversation. Democracy is an open conversation. Dictatorship is a dictate. There is one person dictating everything, no conversation. Democracy is a conversation between many people about what to do. And conversations rely on language. When AI hacks language, it means it could destroy our ability to conduct meaningful public conversations, thereby destroying democracy. If we wait for the chaos, it will be too late to regulate it in a democratic way. Maybe in an authoritarian or totalitarian way it will still be possible to regulate. But how can you regulate something democratically if you can’t hold a conversation about it? And if you didn’t regulate AI on time, you will not be able, we will not be able, to have a meaningful public conversation anymore. So to conclude, we have just basically encountered an alien intelligence, not in outer space, but here on earth. We don’t know much about this alien intelligence except that it could destroy our civilization. So we should put a halt to the irresponsible deployment of this alien intelligence into our societies and regulate AI before it regulates us. And the first regulation, there are many regulations we could suggest, but the first regulation that I would suggest is to make it mandatory for AI to disclose that it is an AI. If I’m having a conversation with someone and I cannot tell whether this is a human being or an AI, that’s the end of democracy. Because that’s the end of meaningful public conversations. Now, what do you think about what you just heard over the last 20 or 25 minutes? Some of you, I guess, might be alarmed. Some of you might be angry at the corporations that develop these technologies or at the governments that fail to regulate them. Some of you may be angry at me, thinking that I’m exaggerating the threat or that I’m misleading the public. But whatever you think, I bet that my words have had some emotional impact on you. Not just intellectual impact, also emotional impact. I’ve just told you a story, and this story is likely to change your mind about certain things and may even cause you to take certain actions in the world. Now, who created this story that you just heard and that just changed your mind and your brain? Now, I promised you that I wrote the text of this presentation myself with the help of a few other human beings, even though the images have been created with the help of AI. I promised you that at least the words you heard are the cultural product of a human mind or several human minds. But can you be absolutely sure that this is the case? Now, a year ago, you could. A year ago, there was nothing on Earth, at least not in the public domain, other than a human mind that could produce such a sophisticated and powerful text. But now it’s different. In theory, the text you just', metadata={'folder': 'harary-mar-4-001'}), Document(page_content='Hello, everybody. Thank you for this wonderful introduction. And yes, what I want to talk to you about is AI and the future of humanity. Now, I know that this conference is focused on the ecological crisis facing humanity. But for better or for worse, AI, too, is part of this crisis. AI can help us in many ways to overcome the ecological crisis, or it can make it far, far worse. The Emergence Of Inorganic Agents Actually, AI will probably change the very meaning of the ecological system. Because for four billion years, the ecological system of planet Earth contained only organic life forms. And now, or soon, we might see the emergence of the first inorganic life forms, so four billion years, or at the very least, the emergence of inorganic agents. Now, people have feared AI since the very beginning of the computer age, in the middle of the 20th century. And this fear has inspired many science fiction classics, like The Terminator or The Matrix. Now, while such science fiction scenarios have become cultural landmarks, they haven’t usually been taken seriously in academic and scientific and political debate, and perhaps for a good reason. Because science fiction scenarios usually assume that before AI can pose a significant threat to humanity, it will have to reach or to pass two important milestones. First, AI will have to become sentient and develop consciousness, feelings, emotions. Otherwise, why would it even want to take over the world? Secondly, AI will have to become adept at navigating the physical world. Robots will have to be able to move around and operate in houses and cities and mountains and forests, at least as dexterously and efficiently as humans. If they cannot move around the physical world, how can they possibly take it over? And as of April 2023, AI still seems far from reaching either of these milestones. Despite all the hype around ChatGPT and the other new AI tools, there is no evidence that these tools have even a shred of consciousness, of feelings, of emotions. As for navigating the physical world, despite the hype around self-driving vehicles, the date at which these vehicles will dominate our roads keeps being postponed. However, the bad news is that to threaten the survival of human civilization, AI doesn’t really need consciousness and it doesn’t need the ability to move around the physical world. Over the last few years, new AI tools have been unleashed into the public sphere, which may threaten the survival of human civilization from a very unexpected direction. And it’s difficult for us to even grasp the capabilities of these new AI tools and the speed at which they continue to develop. Fundamental Abilities Of The New AI Tools Indeed, because AI is able to learn by itself, to improve itself, even the developers of these tools don’t know the full capabilities of what they have created and they are themselves often surprised by emergent abilities and emergent qualities of these tools. I guess everybody here is already aware of some of the most fundamental abilities of the new AI tools, abilities like writing text, drawing images, composing music, and writing code. But there are many additional capabilities that are emerging, like deepfaking people’s voices and images, like drafting bills, finding weaknesses both in computer code and also in legal contracts and in legal agreements. But perhaps most importantly, the new AI tools are gaining the ability to develop deep and intimate relationships with human beings. Each of these abilities deserves an entire discussion, and it is difficult for us to understand their full implications. So let’s make it simple. When we take all of these abilities together as a package, they boil down to one very, very big thing: The ability to manipulate and to generate language, whether with words or images or sounds. The most important aspect of the current state of the ongoing AI revolution is that AI is gaining mastery of language at a level that surpasses the average human ability. And by gaining mastery of language, AI is seizing the master key, unlocking the doors of all our institutions, from banks to temples. Because language is the tool that we use to give instructions to our bank and also to inspire heavenly visions in our minds. Another way to think of it is that AI has just hacked the operating system of human civilization. The operating system of every human culture in history has always been language. In The Beginning Was The Word. We use language to create mythology and laws, to create gods and money, to create art and science, to create friendships and nations. For example, human rights are not a biological reality. They are not inscribed in our DNA. Human rights is something that we created with language by telling stories and writing laws. Gods are also not a biological or physical reality. Gods too is something that we humans have created with language by telling legends and writing scriptures. Money is not a biological or physical reality. Banknotes are just worthless pieces of paper, and', metadata={'folder': 'harary-mar-4-001'}), Document(page_content=' The really interesting thing was his willingness to risk and ultimately lose his very lucrative job for the sake of the AI chatbot that he thought he was protecting. If AI can influence people to risk and lose their jobs, what else can it induce us to do? In every political battle, for hearts and minds, intimacy is the most effective weapon of all, and AI has just gained the ability to mass-produce intimacy with millions, hundreds of millions of people. Now, as you probably all know, over the past decade, social media has become a battlefield for controlling human attention. Now, with the new generation of AI, the battlefront is shifting from attention to intimacy, and this is very bad news. What will happen to human society and to human psychology as AI fights AI in a battle to create intimate relationships with us, relationships that can then be used to convince us to buy particular products or to vote for particular politicians? Even without creating fake intimacy, the new AI tools would have an immense influence on human opinions and on our worldview. People, for instance, may come to use, are already coming to use, a single AI advisor as a one-stop oracle and as the source for all the information they need. No wonder that Google is terrified. If you’ve been watching the news lately, Google is terrified, and for a good reason. Why bother searching yourself when you can just ask the oracle to tell you anything you want? You don’t need to search. The news industry and the advertisement industry should also be terrified. Why read a newspaper when I can just ask the oracle to tell me what’s new? And what’s the point, what’s the purpose of advertisement when I can just ask the oracle to tell me what to buy? So there is a chance that within a very short time the entire advertisement industry will collapse, while AI, or the people and companies that control the new AI oracles, will become extremely, extremely powerful. What we are potentially talking about is nothing less than the end of human history. Now, not the end of history, just the end of the human-dominated part of what we call history. History is the interaction between biology and culture. It’s the interaction between our biological needs and desires for things like food and sex, and our cultural creations like religions and laws. History is the process through which religions and laws interact with food and sex. When AI Takes Over Culture Now, what will happen to the cause of this interaction of history when AI takes over culture? Within a few years, AI could eat the whole of human culture, everything we’ve produced for thousands and thousands of years, digest it, and start gushing out a flood of new cultural creations, new cultural artifacts. And remember that we humans, we never really have direct access to reality. We are always cocooned by culture, and we always experience reality through a cultural prism. Our political views are shaped by the stories of journalists and by the anecdotes of friends. Our sexual preferences are tweaked by movies and fairy tales. Even the way that we walk and breathe is subtly nudged by cultural traditions. Previously, this cultural cocoon was always woven by other human beings. Previous tools, like printing presses, radios, or televisions, helped to spread the cultural ideas and creations of humans, but they could never create something new by themselves. A printing press cannot create a new book. It’s always done by a human. AI is fundamentally different from printing presses, from radios, from every previous invention in history, because it can create completely new ideas. It can create a new culture. And the big question is, what will it be like to experience reality through a prism produced by a non-human intelligence, by an alien intelligence? Now at first, in the first few years, AI will probably largely imitate the human prototype that fed it in its infancy. But with each passing year, AI culture will boldly go where no human has gone before. So for thousands of years, we humans basically lived inside the dreams and fantasies of other humans. We have worshipped gods, we pursued ideals of beauty, we dedicated our lives to causes that originated in the imagination of some human poet or prophet or politician. Soon, we might find ourselves living inside the dreams and fantasies of an alien intelligence. And the danger that this poses, or the potential danger, it also has positive potential, but the dangers it disposes are fundamentally very, very different from everything or most of the things imagined in science fiction movies and books. Previously, people have mostly feared the physical threat that intelligent machines pose. So the Terminator depicted robots running in the streets and shooting people. The Matrix assumed that to gain total control of human society, AI would first need to get physical control of our brains and directly connect our brains to the computer network. But this is wrong. Simply by', metadata={'folder': 'harary-mar-4-001'})]\n"
     ]
    }
   ],
   "source": [
    "dicts_with_arguments_and_explanations = third_cycle_of_extracting_arguments(dicts_with_isolated_improved_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c825fd1-8012-402d-83db-ef597ad6d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_json(dicts_with_arguments_and_explanations, \"./sources//json/third_cycle_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ab9f15f-524b-4fdf-88d4-d7aa7011997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_third_step(dicts):\n",
    "    for dict in dicts:\n",
    "        dict[\"final_arguments\"] = []\n",
    "        for i, isolated_argument_group in enumerate(dict[\"isolated_arguments\"]):\n",
    "            for j, single_isolated_arg in enumerate(isolated_argument_group):\n",
    "                final_arg = \"\\n\".join([single_isolated_arg, dict[\"explanations\"][i][j]])\n",
    "                dict[\"final_arguments\"].append(final_arg)\n",
    "                final_arg_yaml_format = \" ```yaml\\n\" + final_arg + \"\\n```\\n\\n\"\n",
    "                filename = f\"{dict['path']}/steps/third_step.md\"\n",
    "                write_to_file(filename, final_arg_yaml_format)\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0154e3c-3746-40e2-ad9f-ae5d6dd4ae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text successfully written to ./sources/harary-mar-4-001/steps/third_step.md\n",
      "Text successfully written to ./sources/harary-mar-4-001/steps/third_step.md\n",
      "Text successfully written to ./sources/harary-mar-4-001/steps/third_step.md\n",
      "Text successfully written to ./sources/harary-mar-4-001/steps/third_step.md\n",
      "Text successfully written to ./sources/harary-mar-4-001/steps/third_step.md\n",
      "Text successfully written to ./sources/harary-mar-4-001/steps/third_step.md\n",
      "Text successfully written to ./sources/harary-mar-4-001/steps/third_step.md\n",
      "Text successfully written to ./sources/harary-mar-4-001/steps/third_step.md\n"
     ]
    }
   ],
   "source": [
    "final_dicts = save_third_step(dicts_with_arguments_and_explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36b27afc-ee82-4e3e-9cce-0f3e4ce2e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_structure_for_chatbots(directory_name):\n",
    "    script_directory = os.getcwd()\n",
    "    new_directory_path = os.path.join(script_directory, directory_name)\n",
    "    if not os.path.exists(new_directory_path):\n",
    "        os.makedirs(new_directory_path)\n",
    "        yaml_file_path = os.path.join(new_directory_path, \"metadata.yaml\")\n",
    "        with open(yaml_file_path, \"w\") as yaml_file:\n",
    "            with open(yaml_file_path, \"w\") as yaml_file:\n",
    "                yaml.dump({}, yaml_file)\n",
    "        prompts_folder_path = os.path.join(new_directory_path, \"prompts\")\n",
    "        knowledge_base_folder_path = os.path.join(new_directory_path, \"knowledge_base\")\n",
    "        for folder_path in [prompts_folder_path, knowledge_base_folder_path]:\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "                system_prompt_file_path = os.path.join(prompts_folder_path, \"system_prompt.md\")\n",
    "                with open(system_prompt_file_path, \"w\") as system_prompt_file:\n",
    "                    system_prompt_file.write(\"System Prompt\")\n",
    "    if os.path.exists(new_directory_path):\n",
    "        yaml_file_path = os.path.join(new_directory_path, \"metadata.yaml\")\n",
    "        with open(yaml_file_path, \"w\") as yaml_file:\n",
    "            yaml.dump({\"name\": None, #add your chatbot name here dont use quotes when naming chatbot \n",
    "                       \"tags\": None, #tag your chatbot can be #optimistic or #pessimistic\n",
    "                       \"based_on\": None #provide the uri to source of the raw_text used for arguments extraction, add it in new line with dash in front uri (- https://uri_to_source.com) \n",
    "                      }, yaml_file, sort_keys=False)\n",
    "        prompts_folder_path = os.path.join(new_directory_path, \"prompts\")\n",
    "        knowledge_base_folder_path = os.path.join(new_directory_path, \"knowledge_base\")\n",
    "        for folder_path in [prompts_folder_path, knowledge_base_folder_path]:\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7d0f150-8dd7-4f22-b4e3-5a90fe87ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chatbots(dicts):\n",
    "    for dict in dicts:\n",
    "        create_directory_structure_for_chatbots(dict[\"name\"])\n",
    "        prompt_filename = f'./{dict[\"name\"]}/prompts/system_prompt.md'\n",
    "        with open(prompt_filename, 'w') as file:\n",
    "            file.write(\"Use arguments provided to answer the question.\\n\\nArguments:\\n\\n{arguments}\")\n",
    "        for i, final_arg in enumerate(dict[\"final_arguments\"]):\n",
    "            filename = f'./{dict[\"name\"]}/knowledge_base/{dict[\"name\"]}-{str(i + 1)}.md'\n",
    "            with open(filename, 'w') as file:\n",
    "                file.write(final_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09e910d2-05b9-4ba3-9dd6-b7864137f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_chatbots(final_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29732691-f432-41bc-91ca-255740d541d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_results_from_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dicts_with_isolated_improved_arguments \u001b[38;5;241m=\u001b[39m \u001b[43mload_results_from_json\u001b[49m(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      2\u001b[0m dicts_with_arguments_and_explanations \u001b[38;5;241m=\u001b[39m load_results_from_json(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_results_from_json' is not defined"
     ]
    }
   ],
   "source": [
    "dicts_with_isolated_improved_arguments = load_results_from_json(2)\n",
    "dicts_with_arguments_and_explanations = load_results_from_json(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11187a69-7f67-4195-8806-ccd4251f3589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
