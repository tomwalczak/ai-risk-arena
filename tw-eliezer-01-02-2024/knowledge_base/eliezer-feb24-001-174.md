claim: "AI's technical feasibility for augmenting humans is over 1%."
premises:
  - claim: "It is technically feasible to build an artificial general intelligence that applies its intelligence narrowly to augmenting humans."
  - claim: "The current efforts and direction in AI development significantly diverge from focusing on such specific applications."
counterargument_to:
  - AI's technical feasibility for augmenting humans is negligible or too risky to pursue.
  - The focus on AI development should be broad and not narrowed down to augmenting human capabilities.

strongest_objection:
  - The ethical implications and potential unintended consequences of augmenting humans with AI are not fully understood, which could lead to catastrophic outcomes.

consequences_if_true:
  - If it's over 1% technically feasible to build an AI that narrowly focuses on augmenting humans, it opens the door to targeted advancements in human capabilities, potentially leading to significant societal and individual benefits.
  - Such a development strategy could lead to safer paths in AI development by focusing on specific, beneficial applications rather than pursuing uncontrolled general intelligence.
  - A shift in AI development focus could stimulate discussions and policies around AI safety and ethics, promoting a more responsible approach to AI research and deployment.

link_to_ai_safety: This argument highlights the importance of directing AI research towards applications that are not only technically feasible but also safe and beneficial, emphasizing the need for a strategic approach to AI safety.

simple_explanation: Eliezer Yudkowsky suggests that there's more than a 1% chance we could develop AI specifically to enhance human capabilities, but he's not very optimistic about our willingness or ability to pursue this path. The current trajectory of AI development is not aligned with such focused applications, and even if we decided to "shut it all down," to prevent potential risks, we might not follow through with effective strategies for safe and beneficial AI use. This discussion underlines the gap between technical possibility and practical implementation in making AI work for human augmentation.

examples:
  - Attempts to create AI that can diagnose diseases more accurately than human doctors, enhancing the capabilities of healthcare professionals.
  - Development of AI-driven educational tools tailored to individual learning styles, augmenting the educational process.
  - Research into brain-computer interfaces that could augment human cognitive or physical abilities by directly integrating AI.