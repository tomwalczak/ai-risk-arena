claim: "AI safety is compromised by pursuing intelligence without understanding its mechanisms."
premises:
  - claim: "Various methodologies aim to achieve AI intelligence without comprehending the essence of intelligence."
    example: "Including manually programming knowledge, evolutionary computation, studying neuroscience without grasping algorithms, and training large neural networks through gradient descent."
  - claim: "This approach avoids the challenging problem of truly understanding how intelligence functions."
  - claim: "Attempting to achieve intelligence in this manner is considered unwise for humanity."
counterargument_to:
  - AI can safely reach higher levels of intelligence through brute force methods or sheer computational power without fully understanding the underlying mechanisms of intelligence.

strongest_objection:
  - Some argue that the emergent behavior of AI systems can lead to an understanding of intelligence over time, suggesting that comprehension can follow from development rather than precede it.

consequences_if_true:
  - Developing AI without a deep understanding of intelligence mechanisms could lead to unpredictable and potentially dangerous behaviors.
  - It may hinder our ability to control or correct AI systems when they behave in unintended ways.
  - This approach could prevent us from fully unlocking the potential benefits of AI, as a lack of understanding limits our ability to apply AI safely and effectively.

link_to_ai_safety: This argument underscores the importance of understanding the mechanisms of AI to ensure its safe development and application.

simple_explanation: Pursuing artificial intelligence by merely increasing computational power or data without grasping the essence of what intelligence is, is like trying to fly by mimicking a bird's appearance without knowing how wings work. We might get something that looks impressive but fails to soar safely or as intended. This method overlooks the importance of understanding the underlying principles of intelligence, risking the creation of AI systems that are uncontrollable or behave in unexpected ways, which is a direct threat to AI safety.

examples:
  - Manually programming an AI with extensive knowledge databases without understanding how it integrates or applies this knowledge mimics intelligence without grasping its essence.
  - Evolutionary algorithms that simulate thousands of generations of AI development in search of the most effective ones, without comprehending the intelligence these exhibit.
  - Large neural networks trained on extensive datasets through gradient descent that can perform complex tasks but whose decision-making process remains opaque to their creators.